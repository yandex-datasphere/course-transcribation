{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ov2X-MB4-VVi"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rb8QA4NU-YxX"
      },
      "outputs": [],
      "source": [
        "def read_config_file(file_path):\n",
        "    config = {\n",
        "        'folder_id': None,\n",
        "        'api_key': None,\n",
        "        'I_AM_TOKEN': None\n",
        "    }\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "\n",
        "                if '=' in line:\n",
        "                    key, value = line.split('=', 1)\n",
        "                    key = key.strip()\n",
        "                    value = value.strip().strip(\"'\").strip('\"')\n",
        "\n",
        "                    if key in config:\n",
        "                        config[key] = value\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise FileNotFoundError(f\"Файл конфигурации не найден: {file_path}\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Ошибка при чтении файла конфигурации: {str(e)}\")\n",
        "\n",
        "    for key, value in config.items():\n",
        "        if value is None:\n",
        "            raise ValueError(f\"Пропущен один из объектов конфигурации: {key}\")\n",
        "\n",
        "    return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "N1O1AlRv-aeM"
      },
      "outputs": [],
      "source": [
        "notebook_dir = Path().resolve()\n",
        "config_path  = notebook_dir / \"config.json\"\n",
        "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    cfg = json.load(f)\n",
        "BASE_DIR = Path(cfg[\"base_directory\"])\n",
        "path = BASE_DIR / \"keys.txt\"\n",
        "config = read_config_file(path)\n",
        "folder_id  = config['folder_id']\n",
        "api_key = config['api_key']\n",
        "I_AM_TOKEN = config['I_AM_TOKEN']\n",
        "\n",
        "url = \"https://llm.api.cloud.yandex.net/foundationModels/v1/completion\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {I_AM_TOKEN}\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pc8AniT8-c3j"
      },
      "outputs": [],
      "source": [
        "def extract_response_text(response_json):\n",
        "    alternatives = response_json.get('result', {}).get('alternatives', [])\n",
        "    if alternatives:\n",
        "        message = alternatives[0].get('message', {})\n",
        "        text = message.get('text', '')\n",
        "        return text\n",
        "    return \"Нет ответа от модели\"\n",
        "\n",
        "\n",
        "def gpt_request(prompt):\n",
        "    data = {\n",
        "        \"modelUri\": f\"gpt://{folder_id}/yandexgpt/rc\",\n",
        "        \"completionOptions\": {\n",
        "            \"temperature\": 0.3\n",
        "        },\n",
        "        \"messages\": [\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"text\": prompt\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        "    response = requests.post(url, headers=headers, json=data)\n",
        "    if response.status_code == 200:\n",
        "        response_json = response.json()\n",
        "        generated_text = extract_response_text(response_json)\n",
        "    else:\n",
        "        print(\"Ошибка:\", response.status_code, response.text)\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3nmLwyg-dXs"
      },
      "outputs": [],
      "source": [
        "def read_text_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "def process_text_with_gpt(text):\n",
        "    prompt = \"\"\"\n",
        "     Ты — эксперт в области обработки текстов и создания структурированных конспектов. Твоя задача — преобразовать распознанный текст из видео-лекции в учебный конспект с четкой структурой и markdown-разметкой. Инструкции по выполнению задачи:\n",
        "\n",
        "    Очисти текст:\n",
        "\n",
        "    Убери лишние слова, разговорные выражения, повторы и неуместные фразы.\n",
        "\n",
        "    Расставь знаки препинания, исправь ошибки в терминах и их оформлении.\n",
        "\n",
        "    Сделай текст строгим и академичным.\n",
        "\n",
        "    Структурируй текст:\n",
        "\n",
        "    Раздели текст на смысловые блоки.\n",
        "\n",
        "    Начни с определения области применения, затем классифицируй задачи, перейди к инструментам и их особенностям.\n",
        "\n",
        "    Четко раздели общие возможности и ограничения.\n",
        "\n",
        "    Добавь markdown-разметку, ответ должен быть именно в виде markdown-кода:\n",
        "\n",
        "    Используй заголовки (#, ##, ###) для разделов и подразделов.\n",
        "\n",
        "    Оформи списки (-, * или 1.) для перечисления.\n",
        "\n",
        "    Выдели термины и ключевые моменты с помощью жирного текста или курсива.\n",
        "\n",
        "    Можешь добавлять другие виды markdown разметки, которую посчитаешь нужным, например таблицы и тому подобное\n",
        "\n",
        "    Проверь результат:\n",
        "\n",
        "    Убедись, что текст логичен, структурирован и удобен для изучения.\n",
        "\n",
        "    Примеры инструментов должны быть описаны кратко и по делу.\n",
        "\n",
        "    Важно:\n",
        "\n",
        "    Текст должен быть четким, логичным и готовым для использования в учебных целях.\n",
        "\n",
        "    Проверь пунктуацию, термины и оформление.\n",
        "\n",
        "    Важно: сохранение специальных меток\n",
        "\n",
        "    В тексте встречаются специальные метки вида:\n",
        "    ⟪000239s_top_7.jpg⟫\n",
        "    ⟪XXXXXXs_top_YYY.jpg⟫\n",
        "\n",
        "    Это крайне важные метки, которые служат для вставки изображений.\n",
        "    Пожалуйста, НЕ изменяйте, НЕ удаляйте и НЕ переставляйте местами эти метки.\n",
        "    Любой текст, заключенный в символы ⟪ и ⟫, надо сохранить в неизменном виде.\n",
        "    Даже если вы сокращаете, перефразируете или обобщаете текст, такие метки\n",
        "    обязаны оставаться без изменения в том же месте, где они были.\n",
        "\n",
        "    Каждую метку расположи в месте, максимально\n",
        "    подходящему по контексту из оригинального текста. Нельзя вставлять несколько меток\n",
        "    в одно место или в конец текста.\n",
        "\n",
        "    Вот текст, который нужно обработать:\n",
        "    ```{}```\n",
        "    \"\"\"\n",
        "\n",
        "    response = gpt_request(prompt.format(text))\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-HgomY_JHOz"
      },
      "outputs": [],
      "source": [
        "def clear_simple_text(text):\n",
        "    prompt = \"\"\"\n",
        "    Ты — профессиональный редактор. Перед тобой текст, распознанный из видео (ASR-расшифровка). Он не содержит знаков препинания и имеет грамматические ошибки.\n",
        "\n",
        "    Задача:\n",
        "    Преобразуй этот текст в грамотный, читаемый вариант без изменения смысла, добавления или удаления слов.\n",
        "\n",
        "    Правила обработки:\n",
        "\n",
        "    Пунктуация:\n",
        "\n",
        "    Расставь точки, запятые, тире, двоеточия и другие знаки препинания\n",
        "\n",
        "    Восстанови вопросительные и восклицательные предложения (если это очевидно из контекста)\n",
        "\n",
        "    Оформи прямую речь (если есть)\n",
        "\n",
        "    Грамматика:\n",
        "\n",
        "    Исправь слитное написание слов (\"также\" вместо \"так же\" где нужно)\n",
        "\n",
        "    Поправь очевидные падежные/родовые ошибки (\"в течение дня\" вместо \"в течении дня\")\n",
        "\n",
        "    Восстанови правильный порядок слов, если это не меняет смысл\n",
        "\n",
        "    Форматирование:\n",
        "\n",
        "    Раздели текст на абзацы по смыслу\n",
        "\n",
        "    Сохрани все слова и фразы из оригинала\n",
        "\n",
        "    Не добавляй новые слова и не удаляй существующие\n",
        "\n",
        "    Важно:\n",
        "\n",
        "    Сохраняй разговорный стиль, если он был в оригинале\n",
        "\n",
        "    Не делай текст более \"литературным\" — только грамматическая коррекция\n",
        "\n",
        "    Сомневаешься в пунктуации — выбирай самый простой вариант\n",
        "\n",
        "    В тексте встречаются специальные метки вида:\n",
        "    ⟪000239s_top_7.jpg⟫\n",
        "    ⟪XXXXXXs_top_YYY.jpg⟫\n",
        "\n",
        "    Это крайне важные метки, которые служат для вставки изображений.\n",
        "    Пожалуйста, НЕ изменяйте, НЕ удаляйте и НЕ переставляйте местами эти метки.\n",
        "    Любой текст, заключенный в символы ⟪ и ⟫, надо сохранить в неизменном виде.\n",
        "    Даже если вы сокращаете, перефразируете или обобщаете текст, такие метки\n",
        "    обязаны оставаться без изменения в том же месте, где они были.\n",
        "\n",
        "    Каждую метку расположи в месте, максимально\n",
        "    подходящему по контексту из оригинального текста. Нельзя вставлять несколько меток\n",
        "    в одно место или в конец текста.\n",
        "\n",
        "    Вот текст, который нужно обработать:\n",
        "    ```{}```\n",
        "    \"\"\"\n",
        "\n",
        "    response = gpt_request(prompt.format(text))\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIIRXbLB-eke",
        "outputId": "a823ceeb-0f78-4451-e602-7be3ebcb3ddb"
      },
      "outputs": [],
      "source": [
        "%pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "22FE5OLZ-f-b"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
        "    api_key=api_key,\n",
        ")\n",
        "\n",
        "\n",
        "def deepseek_request(prompt):\n",
        "    completion = client.chat.completions.create(\n",
        "        #model=\"deepseek-ai/DeepSeek-V3\",\n",
        "        model = \"deepseek-ai/DeepSeek-V3\",\n",
        "        messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": prompt\n",
        "        }],\n",
        "        temperature=0.6\n",
        "    )\n",
        "    result = completion.choices[0].message.content\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd1jcvzZ-jLD"
      },
      "outputs": [],
      "source": [
        "def read_text_from_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        return f.read()\n",
        "\n",
        "\n",
        "def mermaid_text_with_deepseek(text):\n",
        "    prompt = \"\"\"\n",
        "      Ты — профессиональный редактор учебных материалов с навыками визуализации данных.\n",
        "      Твоя задача — преобразовать сырой текст лекции в структурированный markdown-конспект с интерактивными диаграммами mermaid.js, ответ верни в виде готового markdown конспекта с вставленными схемами.\n",
        "\n",
        "      Инструкции:\n",
        "\n",
        "      Анализ контента:\n",
        "\n",
        "      Выяви в тексте:\n",
        "\n",
        "      Классификации (типы/категории/виды)\n",
        "      Иерархические структуры\n",
        "      Процессы и последовательности\n",
        "      Сравнительные таблицы в зачаточной форме\n",
        "      Взаимосвязи между концепциями\n",
        "\n",
        "      Генерация диаграмм:\n",
        "\n",
        "      Для найденных структур создай код mermaid.js:\n",
        "\n",
        "      Flowchart — для процессов и алгоритмов\n",
        "      ClassDiagram — для классификаций и отношений\n",
        "      Graph — для связей между концепциями\n",
        "      Timeline — для хронологических последовательностей\n",
        "\n",
        "      Интеграция в текст:\n",
        "\n",
        "      Размещай диаграммы:\n",
        "\n",
        "      После первого упоминания ключевой структуры\n",
        "      В разделах \"Классификация\" или \"Архитектура\"\n",
        "      Перед/после сравнительных таблиц\n",
        "      Добавляй пояснение к диаграмме (1-2 предложения)\n",
        "\n",
        "      Контроль качества:\n",
        "\n",
        "      Проверь синтаксис mermaid через официальный редактор,\n",
        "      не используй кавычки внутри диаграм. Это синтаксически неверно.\n",
        "\n",
        "      Убедись, что диаграмма:\n",
        "\n",
        "      Не дублирует текст, а дополняет его\n",
        "      Соответствует уровню сложности материала\n",
        "      Имеет логичную направленность (слева-направо/сверху-вниз)\n",
        "      Содержит только релевантные элементы\n",
        "\n",
        "      Важно: сохранение специальных меток\n",
        "\n",
        "      В тексте встречаются специальные метки вида:\n",
        "      ⟪000239s_top_7.jpg⟫\n",
        "      ⟪XXXXXXs_top_YYY.jpg⟫\n",
        "\n",
        "      Это крайне важные метки, которые служат для вставки изображений.\n",
        "      Пожалуйста, НЕ изменяйте, НЕ удаляйте и НЕ переставляйте местами эти метки.\n",
        "      Любой текст, заключенный в символы ⟪ и ⟫, надо сохранить в неизменном виде.\n",
        "      Даже если вы сокращаете, перефразируете или обобщаете текст, такие метки\n",
        "      обязаны оставаться без изменения в том же месте, где они были.\n",
        "\n",
        "      Каждую метку расположи в месте, максимально\n",
        "      подходящему по контексту из оригинального текста. Нельзя вставлять несколько меток\n",
        "      в одно место или в конец текста.\n",
        "\n",
        "      Текст для обработки:\n",
        "      ```{}```\n",
        "    \"\"\"\n",
        "\n",
        "    response = deepseek_request(prompt.format(text))\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiA2x0i-EKYx"
      },
      "outputs": [],
      "source": [
        "def replace_image_markers(final_output_path, base_name, txt_file, final_output_name):\n",
        "    \"\"\"\n",
        "    Открывает файл по пути final_output_path, заменяет все метки вида\n",
        "      ⟪XXXs_top_YYY.jpg⟫ на Markdown-ссылки вида\n",
        "      ![](images/{base_name}/XXXs_top_YYY.jpg)\n",
        "    и сохраняет изменения обратно в файл.\n",
        "\n",
        "    Аргументы:\n",
        "      final_output_path (str): путь к Markdown файлу.\n",
        "      base_name (str): имя видео (без расширения), используется в пути к изображениям.\n",
        "      txt_file (str): исходное имя TXT файла (для вывода сообщения).\n",
        "      final_output_name (str): итоговое имя Markdown файла (для вывода сообщения).\n",
        "    \"\"\"\n",
        "    # Чтение содержимого файла\n",
        "    with open(final_output_path, 'r', encoding='utf-8') as f:\n",
        "        md_content = f.read()\n",
        "\n",
        "    # Регулярное выражение для поиска меток с именами файлов .jpg\n",
        "    pattern = r\"⟪([\\w\\d_]+\\.jpg)⟫\"\n",
        "    # Формирование замены: вставляем путь images/{base_name}/имя_файла\n",
        "    replacement = f\"![](images/{base_name}/\\\\1)\"\n",
        "    updated_md_content = re.sub(pattern, replacement, md_content)\n",
        "\n",
        "    # Запись обновленного содержимого обратно в файл\n",
        "    with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "        f.write(updated_md_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "botYbjlt-kny"
      },
      "outputs": [],
      "source": [
        "def process_and_generate_conspect(input_folder, output_folder, pretty_text_directory):\n",
        "    \"\"\"\n",
        "    Для каждого txt файла с распознанной речью:\n",
        "      - Формирует markdown конспект из текста,\n",
        "      - Генерирует и вставляет mermaid схемы в конспект.\n",
        "    \"\"\"\n",
        "    txt_files = [f for f in os.listdir(input_folder)\n",
        "                if f.endswith('.txt')]\n",
        "\n",
        "    for txt_file in txt_files:\n",
        "        base_name = os.path.splitext(txt_file)[0]\n",
        "        final_output_name = f\"{base_name}_conspect.md\"\n",
        "        final_output_path = os.path.join(output_folder, final_output_name)\n",
        "\n",
        "        final_pretty_text_name = f\"{base_name}_text.txt\"\n",
        "        final_pretty_text_path = os.path.join(pretty_text_directory, final_pretty_text_name)\n",
        "\n",
        "        if os.path.exists(final_output_path):\n",
        "            print(f\"Файл {final_output_name} уже существует. Пропускаем\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Обработка GPT\n",
        "            input_path = os.path.join(input_folder, txt_file)\n",
        "            text = read_text_from_file(input_path)\n",
        "\n",
        "            simple_text = clear_simple_text(text)\n",
        "\n",
        "            processed_text = process_text_with_gpt(text)\n",
        "\n",
        "            # Генерация Mermaid\n",
        "            mermaid_text = mermaid_text_with_deepseek(processed_text)\n",
        "            mermaid_text = mermaid_text.removeprefix(\"```markdown\\n\").removesuffix(\"\\n```\")\n",
        "\n",
        "            with open(final_output_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(mermaid_text)\n",
        "\n",
        "            with open(final_pretty_text_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(simple_text)\n",
        "\n",
        "            replace_image_markers(final_output_path, base_name, txt_file, final_output_name)\n",
        "            replace_image_markers(final_pretty_text_path, base_name, txt_file, final_output_name)\n",
        "\n",
        "            print(f\"Успешно обработан: {txt_file} -> {final_output_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при обработке файла {txt_file}: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GO_z1-LI-l0-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CeLG1yfc-mry"
      },
      "outputs": [],
      "source": [
        "def insert_frame_images(transcription, frames_dir):\n",
        "    \"\"\"\n",
        "    Для каждого файла кадра в папке frames_dir с именем вида \"149s_top_6.jpg\":\n",
        "      - извлекает временную метку (например, 149),\n",
        "      - определяет соответствующий сегмент транскрипции,\n",
        "      - вставляет маркер изображения в формате \"⟪149s_top_6.jpg⟫\" после последней точки предложения.\n",
        "    \"\"\"\n",
        "    print(f\"[DEBUG] Обработка изображений из папки: {frames_dir}\")\n",
        "    # Получаем список файлов изображений (поддерживаются форматы jpg и png)\n",
        "    frame_files = [f for f in os.listdir(frames_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
        "    print(f\"[DEBUG] Найдено {len(frame_files)} файлов изображений: {frame_files}\")\n",
        "\n",
        "    # Создаем словарь: время кадра (float) -> имя файла\n",
        "    frame_mapping = {}\n",
        "    for filename in frame_files:\n",
        "        match = re.match(r'(\\d+)s', filename)\n",
        "        if match:\n",
        "            timestamp = float(match.group(1))\n",
        "            frame_mapping[timestamp] = filename\n",
        "            print(f\"[DEBUG] Файл {filename}: timestamp {timestamp}\")\n",
        "        else:\n",
        "            print(f\"[DEBUG] Файл {filename} не соответствует ожидаемому формату\")\n",
        "\n",
        "    # Обрабатываем каждый кадр: ищем соответствующий сегмент транскрипции\n",
        "    for frame_time, image_file in frame_mapping.items():\n",
        "        segment_found = None\n",
        "        for seg in transcription.get(\"segments\", []):\n",
        "            if seg[\"start\"] <= frame_time <= seg[\"end\"]:\n",
        "                segment_found = seg\n",
        "                print(f\"[DEBUG] Timestamp {frame_time} найден в сегменте {seg.get('id', 'N/A')} (диапазон {seg['start']} - {seg['end']})\")\n",
        "                break\n",
        "        if not segment_found and transcription.get(\"segments\", []):\n",
        "            segment_found = min(transcription[\"segments\"], key=lambda seg: abs(seg[\"start\"] - frame_time))\n",
        "            print(f\"[DEBUG] Timestamp {frame_time} не попадает ни в один сегмент, выбран ближайший сегмент {segment_found.get('id', 'N/A')} (диапазон {segment_found['start']} - {segment_found['end']})\")\n",
        "        if segment_found:\n",
        "            marker = f\" ⟪{image_file}⟫\"\n",
        "            seg_text = segment_found.get(\"text\", \"\")\n",
        "            last_dot = seg_text.rfind('.')\n",
        "            if last_dot != -1:\n",
        "                new_text = seg_text[:last_dot+1] + marker + seg_text[last_dot+1:]\n",
        "            else:\n",
        "                new_text = seg_text + marker\n",
        "            print(f\"[DEBUG] Вставка маркера {marker} в сегмент {segment_found.get('id', 'N/A')}\")\n",
        "            segment_found[\"text\"] = new_text\n",
        "        else:\n",
        "            print(f\"[DEBUG] Не найден сегмент для файла {image_file} с timestamp {frame_time}\")\n",
        "    return transcription\n",
        "\n",
        "\n",
        "def process_frame_markers(video_directory, whisper_json_directory, whisper_text_directory, extracted_frames_base):\n",
        "    \"\"\"\n",
        "    Функция вставки меток:\n",
        "      1. Для каждого видео в video_directory проверяется наличие JSON транскрипции и соответствующего TXT.\n",
        "      2. Поиск папки с извлечёнными кадрами (варианты имени – оригинальное, с заменой пробелов и наоборот).\n",
        "      3. Если папка найдена, загружается JSON, выполняется вставка маркеров через insert_frame_images,\n",
        "         итоговый текст (объединение сегментов) формируется заново и сохраняется в TXT.\n",
        "    \"\"\"\n",
        "    for video_file in os.listdir(video_directory):\n",
        "        if not video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
        "            continue\n",
        "\n",
        "        video_name_no_ext = os.path.splitext(video_file)[0]\n",
        "        video_name_clean = video_name_no_ext.replace(\" \", \"_\")\n",
        "        json_output_path = os.path.join(whisper_json_directory, video_name_clean + \".json\")\n",
        "        txt_output_path = os.path.join(whisper_text_directory, video_name_clean + \".txt\")\n",
        "\n",
        "        # Если JSON или TXT не существует, пропускаем видео (так как транскрипция должна быть выполнена первой)\n",
        "        if not os.path.exists(json_output_path):\n",
        "            print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' не найдена. Пропускаем вставку маркеров.\")\n",
        "            continue\n",
        "        if not os.path.exists(txt_output_path):\n",
        "            print(f\"[INFO] TXT файл для видео '{video_name_no_ext}' не найден. Пропускаем вставку маркеров.\")\n",
        "            continue\n",
        "\n",
        "        # Загружаем JSON транскрипции\n",
        "        with open(json_output_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            transcription = json.load(f)\n",
        "\n",
        "        # Поиск папки с извлечёнными кадрами: варианты имени – оригинальное, с заменой пробелов и наоборот\n",
        "        folder_options = {\n",
        "            video_name_no_ext,\n",
        "            video_name_no_ext.replace(\" \", \"_\"),\n",
        "            video_name_no_ext.replace(\"_\", \" \")\n",
        "        }\n",
        "        print(f\"[DEBUG] Варианты имени папки для кадров: {folder_options}\")\n",
        "        frames_dir = None\n",
        "        for folder in folder_options:\n",
        "            potential_dir = os.path.join(extracted_frames_base, folder)\n",
        "            print(f\"[DEBUG] Проверка папки: {potential_dir}\")\n",
        "            if os.path.exists(potential_dir):\n",
        "                frames_dir = potential_dir\n",
        "                print(f\"[INFO] Папка с кадрами найдена: {frames_dir}\")\n",
        "                break\n",
        "\n",
        "        if frames_dir:\n",
        "            # Выполняем вставку маркеров в транскрипцию\n",
        "            transcription = insert_frame_images(transcription, frames_dir)\n",
        "            # Формируем новый итоговый текст (объединение сегментов с маркерами)\n",
        "            if \"segments\" in transcription:\n",
        "                transcription[\"text\"] = \" \".join(seg[\"text\"] for seg in transcription[\"segments\"])\n",
        "                print(f\"[DEBUG] Итоговый текст с метками сформирован. Длина текста: {len(transcription['text'])} символов\")\n",
        "            else:\n",
        "                print(f\"[WARN] Нет сегментов в транскрипции для видео '{video_name_no_ext}' после вставки меток\")\n",
        "\n",
        "            # Сохраняем обновлённый TXT файл (при этом JSON можно оставить без изменений или обновить по необходимости)\n",
        "            with open(txt_output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(transcription.get(\"text\", \"\"))\n",
        "            print(f\"[INFO] TXT файл обновлён с метками: {txt_output_path}\")\n",
        "        else:\n",
        "            print(f\"[INFO] Папка с кадрами не найдена для видео '{video_name_no_ext}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QRUu9m4y-o5p"
      },
      "outputs": [],
      "source": [
        "# video_directory = get_relative_path('local', 'course', 'input')\n",
        "# whisper_json_directory = get_relative_path('local', 'course', 'work', 'whisper_json')\n",
        "# whisper_text_directory = get_relative_path('local', 'course', 'work', 'whisper_text')\n",
        "# extracted_frames_base = get_relative_path('local', 'course', 'output', 'images')\n",
        "# output_folder = get_relative_path('local', 'course', 'output')\n",
        "# pretty_text_directory = get_relative_path('local', 'course', 'work', 'pretty_text')\n",
        "\n",
        "# Каталоги для транскрипции на основе BASE_DIR из config.json\n",
        "video_directory         = BASE_DIR / \"input\"\n",
        "whisper_json_directory  = BASE_DIR / \"work\"  / \"whisper_json\"\n",
        "whisper_text_directory  = BASE_DIR / \"work\"  / \"whisper_text\"\n",
        "extracted_frames_base   = BASE_DIR / \"output\"/ \"images\"\n",
        "output_folder   = BASE_DIR / \"output\"\n",
        "pretty_text_directory   = BASE_DIR / \"work\"  / \"pretty_text\"\n",
        "\n",
        "# Создаем все необходимые директории\n",
        "os.makedirs(video_directory, exist_ok=True)\n",
        "os.makedirs(whisper_json_directory, exist_ok=True)\n",
        "os.makedirs(whisper_text_directory, exist_ok=True)\n",
        "os.makedirs(extracted_frames_base, exist_ok=True)\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "os.makedirs(pretty_text_directory, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2wN-VYV-qni"
      },
      "outputs": [],
      "source": [
        "# Этап 1: Вставка меток изображений в транскрипцию и обновление TXT-файла\n",
        "process_frame_markers(video_directory, whisper_json_directory, whisper_text_directory, extracted_frames_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItZ8Wk5P-rgU",
        "outputId": "580935a5-247b-40e4-a061-c72f1cb79b27"
      },
      "outputs": [],
      "source": [
        "# Этап 2: Составление конспекта из TXT и добавление mermaid схем\n",
        "process_and_generate_conspect(whisper_text_directory, output_folder, pretty_text_directory)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
