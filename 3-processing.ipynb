{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e39615-0826-42ec-9df7-72d3030d25df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:37:44.607650Z",
     "iopub.status.busy": "2025-04-03T16:37:44.606670Z",
     "iopub.status.idle": "2025-04-03T16:37:44.898972Z",
     "shell.execute_reply": "2025-04-03T16:37:44.897571Z",
     "shell.execute_reply.started": "2025-04-03T16:37:44.607603Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e5864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config_file(file_path):\n",
    "    config = {\n",
    "        'folder_id': None,\n",
    "        'api_key': None,\n",
    "        'I_AM_TOKEN': None\n",
    "    }\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                if '=' in line:\n",
    "                    key, value = line.split('=', 1)\n",
    "                    key = key.strip()\n",
    "                    value = value.strip().strip(\"'\").strip('\"')\n",
    "                    \n",
    "                    if key in config:\n",
    "                        config[key] = value\n",
    "                        \n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"Файл конфигурации не найден: {file_path}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Ошибка при чтении файла конфигурации: {str(e)}\")\n",
    "\n",
    "    for key, value in config.items():\n",
    "        if value is None:\n",
    "            raise ValueError(f\"Пропущен один из объектов конфигурации: {key}\")\n",
    "    \n",
    "    return config\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a8cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = read_config_file('/content/keys.txt')\n",
    "folder_id  = config['folder_id']\n",
    "api_key = config['api_key']\n",
    "I_AM_TOKEN = config['I_AM_TOKEN']\n",
    "url = \"https://llm.api.cloud.yandex.net/foundationModels/v1/completion\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {I_AM_TOKEN}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1556241f-1087-4753-904a-4fb7140c641a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:37:47.050234Z",
     "iopub.status.busy": "2025-04-03T16:37:47.049060Z",
     "iopub.status.idle": "2025-04-03T16:37:47.066153Z",
     "shell.execute_reply": "2025-04-03T16:37:47.065281Z",
     "shell.execute_reply.started": "2025-04-03T16:37:47.050197Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_response_text(response_json):\n",
    "    alternatives = response_json.get('result', {}).get('alternatives', [])\n",
    "    if alternatives:\n",
    "        message = alternatives[0].get('message', {})\n",
    "        text = message.get('text', '')\n",
    "        return text\n",
    "    return \"Нет ответа от модели\"\n",
    "\n",
    "\n",
    "def gpt_request(prompt):\n",
    "    data = {\n",
    "        \"modelUri\": f\"gpt://{folder_id}/yandexgpt/rc\",\n",
    "        \"completionOptions\": {\n",
    "            \"temperature\": 0.3\n",
    "        },\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"text\": prompt\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        response_json = response.json()\n",
    "        generated_text = extract_response_text(response_json)\n",
    "    else:\n",
    "        print(\"Ошибка:\", response.status_code, response.text)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353266f3-d6be-4493-897f-87bcd543bce2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:37:47.861876Z",
     "iopub.status.busy": "2025-04-03T16:37:47.860423Z",
     "iopub.status.idle": "2025-04-03T16:37:47.892194Z",
     "shell.execute_reply": "2025-04-03T16:37:47.891411Z",
     "shell.execute_reply.started": "2025-04-03T16:37:47.861828Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def process_text_with_gpt(text):\n",
    "    prompt = \"\"\"\n",
    "     Ты — эксперт в области обработки текстов и создания структурированных конспектов. Твоя задача — преобразовать распознанный текст из видео-лекции в учебный конспект с четкой структурой и markdown-разметкой. Инструкции по выполнению задачи:\n",
    "\n",
    "    Очисти текст:\n",
    "\n",
    "    Убери лишние слова, разговорные выражения, повторы и неуместные фразы.\n",
    "\n",
    "    Расставь знаки препинания, исправь ошибки в терминах и их оформлении.\n",
    "\n",
    "    Сделай текст строгим и академичным.\n",
    "\n",
    "    Структурируй текст:\n",
    "\n",
    "    Раздели текст на смысловые блоки.\n",
    "\n",
    "    Начни с определения области применения, затем классифицируй задачи, перейди к инструментам и их особенностям.\n",
    "\n",
    "    Четко раздели общие возможности и ограничения.\n",
    "\n",
    "    Добавь markdown-разметку, ответ должен быть именно в виде markdown-кода:\n",
    "\n",
    "    Используй заголовки (#, ##, ###) для разделов и подразделов.\n",
    "\n",
    "    Оформи списки (-, * или 1.) для перечисления.\n",
    "\n",
    "    Выдели термины и ключевые моменты с помощью жирного текста или курсива.\n",
    "\n",
    "    Можешь добавлять другие виды markdown разметки, которую посчитаешь нужным, например таблицы и тому подобное\n",
    "\n",
    "    Проверь результат:\n",
    "\n",
    "    Убедись, что текст логичен, структурирован и удобен для изучения.\n",
    "\n",
    "    Примеры инструментов должны быть описаны кратко и по делу.\n",
    "\n",
    "    Важно:\n",
    "\n",
    "    Текст должен быть четким, логичным и готовым для использования в учебных целях.\n",
    "\n",
    "    Проверь пунктуацию, термины и оформление.\n",
    "    \n",
    "    Важно: сохранение специальных меток\n",
    "\n",
    "    В тексте встречаются специальные метки вида:\n",
    "    ⟪239s_top_7.jpg⟫ \n",
    "    ⟪XXXs_top_YYY.jpg⟫\n",
    "\n",
    "    Это крайне важные метки, которые служат для вставки изображений.\n",
    "    Пожалуйста, НЕ изменяйте, НЕ удаляйте и НЕ переставляйте местами эти метки.\n",
    "    Любой текст, заключенный в символы ⟪ и ⟫, надо сохранить в неизменном виде.\n",
    "    Даже если вы сокращаете, перефразируете или обобщаете текст, такие метки\n",
    "    обязаны оставаться без изменения в том же месте, где они были.\n",
    "\n",
    "    Вот текст, который нужно обработать:\n",
    "    ```{}```\n",
    "    \"\"\"\n",
    "    \n",
    "    response = gpt_request(prompt.format(text))\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116a4a50-41c0-41b8-bd3a-74b12ee61722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:37:50.217255Z",
     "iopub.status.busy": "2025-04-03T16:37:50.216079Z",
     "iopub.status.idle": "2025-04-03T16:37:55.211067Z",
     "shell.execute_reply": "2025-04-03T16:37:55.209895Z",
     "shell.execute_reply.started": "2025-04-03T16:37:50.217205Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a45ae-3671-48c6-a56b-8a642993b5c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:38:15.297679Z",
     "iopub.status.busy": "2025-04-03T16:38:15.296763Z",
     "iopub.status.idle": "2025-04-03T16:38:15.496894Z",
     "shell.execute_reply": "2025-04-03T16:38:15.495248Z",
     "shell.execute_reply.started": "2025-04-03T16:38:15.297636Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.ai/v1/\",\n",
    "    api_key=api_key,\n",
    ")\n",
    "\n",
    "\n",
    "def deepseek_request(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        #model=\"deepseek-ai/DeepSeek-V3\",\n",
    "        model = \"deepseek-ai/DeepSeek-V3\",\n",
    "        messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        temperature=0.6\n",
    "    ) \n",
    "    result = completion.choices[0].message.content\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6005c55a-df6c-4da1-b1c8-af396a5f2c3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:01:08.248159Z",
     "iopub.status.busy": "2025-04-03T16:01:08.246187Z",
     "iopub.status.idle": "2025-04-03T16:01:08.272117Z",
     "shell.execute_reply": "2025-04-03T16:01:08.270901Z",
     "shell.execute_reply.started": "2025-04-03T16:01:08.248107Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_text_from_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def mermaid_text_with_deepseek(text):\n",
    "    prompt = \"\"\"\n",
    "      Ты — профессиональный редактор учебных материалов с навыками визуализации данных.\n",
    "      Твоя задача — преобразовать сырой текст лекции в структурированный markdown-конспект с интерактивными диаграммами mermaid.js, ответ верни в виде готового markdown конспекта с вставленными схемами.\n",
    "\n",
    "      Инструкции:\n",
    "\n",
    "      Анализ контента:\n",
    "\n",
    "      Выяви в тексте:\n",
    "\n",
    "      Классификации (типы/категории/виды)\n",
    "      Иерархические структуры\n",
    "      Процессы и последовательности\n",
    "      Сравнительные таблицы в зачаточной форме\n",
    "      Взаимосвязи между концепциями\n",
    "\n",
    "      Генерация диаграмм:\n",
    "\n",
    "      Для найденных структур создай код mermaid.js:\n",
    "\n",
    "      Flowchart — для процессов и алгоритмов\n",
    "      ClassDiagram — для классификаций и отношений\n",
    "      Graph — для связей между концепциями\n",
    "      Timeline — для хронологических последовательностей\n",
    "\n",
    "      Интеграция в текст:\n",
    "\n",
    "      Размещай диаграммы:\n",
    "\n",
    "      После первого упоминания ключевой структуры\n",
    "      В разделах \"Классификация\" или \"Архитектура\"\n",
    "      Перед/после сравнительных таблиц\n",
    "      Добавляй пояснение к диаграмме (1-2 предложения)\n",
    "\n",
    "      Контроль качества:\n",
    "\n",
    "      Проверь синтаксис mermaid через официальный редактор,\n",
    "      не используй кавычки внутри диаграм. Это синтаксически неверно.\n",
    "\n",
    "      Убедись, что диаграмма:\n",
    "\n",
    "      Не дублирует текст, а дополняет его\n",
    "      Соответствует уровню сложности материала\n",
    "      Имеет логичную направленность (слева-направо/сверху-вниз)\n",
    "      Содержит только релевантные элементы\n",
    "      \n",
    "      Важно: сохранение специальных меток\n",
    "\n",
    "      В тексте встречаются специальные метки вида:\n",
    "      ⟪239s_top_7.jpg⟫ \n",
    "      ⟪XXXs_top_YYY.jpg⟫\n",
    "\n",
    "      Это крайне важные метки, которые служат для вставки изображений.\n",
    "      Пожалуйста, НЕ изменяйте, НЕ удаляйте и НЕ переставляйте местами эти метки.\n",
    "      Любой текст, заключенный в символы ⟪ и ⟫, надо сохранить в неизменном виде.\n",
    "      Даже если вы сокращаете, перефразируете или обобщаете текст, такие метки\n",
    "      обязаны оставаться без изменения в том же месте, где они были.\n",
    "\n",
    "      Текст для обработки:\n",
    "      ```{}```\n",
    "    \"\"\"\n",
    "\n",
    "    response = deepseek_request(prompt.format(text))\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec0e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_image_markers(final_output_path, base_name, txt_file, final_output_name):\n",
    "    \"\"\"\n",
    "    Открывает файл по пути final_output_path, заменяет все метки вида\n",
    "      ⟪XXXs_top_YYY.jpg⟫ на Markdown-ссылки вида\n",
    "      ![](images/{base_name}/XXXs_top_YYY.jpg)\n",
    "    и сохраняет изменения обратно в файл.\n",
    "    \n",
    "    Аргументы:\n",
    "      final_output_path (str): путь к Markdown файлу.\n",
    "      base_name (str): имя видео (без расширения), используется в пути к изображениям.\n",
    "      txt_file (str): исходное имя TXT файла (для вывода сообщения).\n",
    "      final_output_name (str): итоговое имя Markdown файла (для вывода сообщения).\n",
    "    \"\"\"\n",
    "    # Чтение содержимого файла\n",
    "    with open(final_output_path, 'r', encoding='utf-8') as f:\n",
    "        md_content = f.read()\n",
    "    \n",
    "    # Регулярное выражение для поиска меток с именами файлов .jpg\n",
    "    pattern = r\"⟪([\\w\\d_]+\\.jpg)⟫\"\n",
    "    # Формирование замены: вставляем путь images/{base_name}/имя_файла\n",
    "    replacement = f\"![](images/{base_name}/\\\\1)\"\n",
    "    updated_md_content = re.sub(pattern, replacement, md_content)\n",
    "    \n",
    "    # Запись обновленного содержимого обратно в файл\n",
    "    with open(final_output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(updated_md_content)\n",
    "    \n",
    "    print(f\"Успешно обработан: {txt_file} -> {final_output_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dcec5-730d-41e7-a27f-f1e0138eab7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T16:01:23.506246Z",
     "iopub.status.busy": "2025-04-03T16:01:23.504765Z",
     "iopub.status.idle": "2025-04-03T16:02:01.785133Z",
     "shell.execute_reply": "2025-04-03T16:02:01.783983Z",
     "shell.execute_reply.started": "2025-04-03T16:01:23.506194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_and_generate_conspect(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Для каждого txt файла с распознанной речью:\n",
    "      - Формирует markdown конспект из текста,\n",
    "      - Генерирует и вставляет mermaid схемы в конспект.\n",
    "    \"\"\"\n",
    "    txt_files = [f for f in os.listdir(input_folder) \n",
    "                if f.endswith('.txt')]\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        base_name = os.path.splitext(txt_file)[0]\n",
    "        final_output_name = f\"{base_name}_conspect.md\"\n",
    "        final_output_path = os.path.join(output_folder, final_output_name)\n",
    "        \n",
    "        if os.path.exists(final_output_path):\n",
    "            print(f\"Файл {final_output_name} уже существует. Пропускаем\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Обработка GPT\n",
    "            input_path = os.path.join(input_folder, txt_file)\n",
    "            text = read_text_from_file(input_path)\n",
    "            processed_text = process_text_with_gpt(text)\n",
    "            \n",
    "            # Генерация Mermaid\n",
    "            mermaid_text = mermaid_text_with_deepseek(processed_text)\n",
    "            mermaid_text = mermaid_text.removeprefix(\"```markdown\\n\").removesuffix(\"\\n```\")\n",
    "            \n",
    "            with open(final_output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(mermaid_text)\n",
    "\n",
    "            replace_image_markers(final_output_path, base_name, txt_file, final_output_name)\n",
    "                \n",
    "            print(f\"Успешно обработан: {txt_file} -> {final_output_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке файла {txt_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34076ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6159e-ea5d-49b8-87b7-f3e88671701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_frame_images(transcription, frames_dir):\n",
    "    \"\"\"\n",
    "    Для каждого файла кадра в папке frames_dir с именем вида \"149s_top_6.jpg\":\n",
    "      - извлекает временную метку (например, 149),\n",
    "      - определяет соответствующий сегмент транскрипции,\n",
    "      - вставляет маркер изображения в формате \"⟪149s_top_6.jpg⟫\" после последней точки предложения.\n",
    "    \"\"\"\n",
    "    print(f\"[DEBUG] Обработка изображений из папки: {frames_dir}\")\n",
    "    # Получаем список файлов изображений (поддерживаются форматы jpg и png)\n",
    "    frame_files = [f for f in os.listdir(frames_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "    print(f\"[DEBUG] Найдено {len(frame_files)} файлов изображений: {frame_files}\")\n",
    "    \n",
    "    # Создаем словарь: время кадра (float) -> имя файла\n",
    "    frame_mapping = {}\n",
    "    for filename in frame_files:\n",
    "        match = re.match(r'(\\d+)s', filename)\n",
    "        if match:\n",
    "            timestamp = float(match.group(1))\n",
    "            frame_mapping[timestamp] = filename\n",
    "            print(f\"[DEBUG] Файл {filename}: timestamp {timestamp}\")\n",
    "        else:\n",
    "            print(f\"[DEBUG] Файл {filename} не соответствует ожидаемому формату\")\n",
    "    \n",
    "    # Обрабатываем каждый кадр: ищем соответствующий сегмент транскрипции\n",
    "    for frame_time, image_file in frame_mapping.items():\n",
    "        segment_found = None\n",
    "        for seg in transcription.get(\"segments\", []):\n",
    "            if seg[\"start\"] <= frame_time <= seg[\"end\"]:\n",
    "                segment_found = seg\n",
    "                print(f\"[DEBUG] Timestamp {frame_time} найден в сегменте {seg.get('id', 'N/A')} (диапазон {seg['start']} - {seg['end']})\")\n",
    "                break\n",
    "        if not segment_found and transcription.get(\"segments\", []):\n",
    "            segment_found = min(transcription[\"segments\"], key=lambda seg: abs(seg[\"start\"] - frame_time))\n",
    "            print(f\"[DEBUG] Timestamp {frame_time} не попадает ни в один сегмент, выбран ближайший сегмент {segment_found.get('id', 'N/A')} (диапазон {segment_found['start']} - {segment_found['end']})\")\n",
    "        if segment_found:\n",
    "            marker = f\" ⟪{image_file}⟫\"\n",
    "            seg_text = segment_found.get(\"text\", \"\")\n",
    "            last_dot = seg_text.rfind('.')\n",
    "            if last_dot != -1:\n",
    "                new_text = seg_text[:last_dot+1] + marker + seg_text[last_dot+1:]\n",
    "            else:\n",
    "                new_text = seg_text + marker\n",
    "            print(f\"[DEBUG] Вставка маркера {marker} в сегмент {segment_found.get('id', 'N/A')}\")\n",
    "            segment_found[\"text\"] = new_text\n",
    "        else:\n",
    "            print(f\"[DEBUG] Не найден сегмент для файла {image_file} с timestamp {frame_time}\")\n",
    "    return transcription\n",
    "\n",
    "\n",
    "def process_frame_markers(video_directory, whisper_json_directory, whisper_text_directory, extracted_frames_base):\n",
    "    \"\"\"\n",
    "    Функция вставки меток:\n",
    "      1. Для каждого видео в video_directory проверяется наличие JSON транскрипции и соответствующего TXT.\n",
    "      2. Поиск папки с извлечёнными кадрами (варианты имени – оригинальное, с заменой пробелов и наоборот).\n",
    "      3. Если папка найдена, загружается JSON, выполняется вставка маркеров через insert_frame_images,\n",
    "         итоговый текст (объединение сегментов) формируется заново и сохраняется в TXT.\n",
    "    \"\"\"\n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if not video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            continue\n",
    "        \n",
    "        video_name_no_ext = os.path.splitext(video_file)[0]\n",
    "        video_name_clean = video_name_no_ext.replace(\" \", \"_\")\n",
    "        json_output_path = os.path.join(whisper_json_directory, video_name_clean + \".json\")\n",
    "        txt_output_path = os.path.join(whisper_text_directory, video_name_clean + \".txt\")\n",
    "        \n",
    "        # Если JSON или TXT не существует, пропускаем видео (так как транскрипция должна быть выполнена первой)\n",
    "        if not os.path.exists(json_output_path):\n",
    "            print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' не найдена. Пропускаем вставку маркеров.\")\n",
    "            continue\n",
    "        if not os.path.exists(txt_output_path):\n",
    "            print(f\"[INFO] TXT файл для видео '{video_name_no_ext}' не найден. Пропускаем вставку маркеров.\")\n",
    "            continue\n",
    "        \n",
    "        # Загружаем JSON транскрипции\n",
    "        with open(json_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            transcription = json.load(f)\n",
    "        \n",
    "        # Поиск папки с извлечёнными кадрами: варианты имени – оригинальное, с заменой пробелов и наоборот\n",
    "        folder_options = {\n",
    "            video_name_no_ext,\n",
    "            video_name_no_ext.replace(\" \", \"_\"),\n",
    "            video_name_no_ext.replace(\"_\", \" \")\n",
    "        }\n",
    "        print(f\"[DEBUG] Варианты имени папки для кадров: {folder_options}\")\n",
    "        frames_dir = None\n",
    "        for folder in folder_options:\n",
    "            potential_dir = os.path.join(extracted_frames_base, folder)\n",
    "            print(f\"[DEBUG] Проверка папки: {potential_dir}\")\n",
    "            if os.path.exists(potential_dir):\n",
    "                frames_dir = potential_dir\n",
    "                print(f\"[INFO] Папка с кадрами найдена: {frames_dir}\")\n",
    "                break\n",
    "        \n",
    "        if frames_dir:\n",
    "            # Выполняем вставку маркеров в транскрипцию\n",
    "            transcription = insert_frame_images(transcription, frames_dir)\n",
    "            # Формируем новый итоговый текст (объединение сегментов с маркерами)\n",
    "            if \"segments\" in transcription:\n",
    "                transcription[\"text\"] = \" \".join(seg[\"text\"] for seg in transcription[\"segments\"])\n",
    "                print(f\"[DEBUG] Итоговый текст с метками сформирован. Длина текста: {len(transcription['text'])} символов\")\n",
    "            else:\n",
    "                print(f\"[WARN] Нет сегментов в транскрипции для видео '{video_name_no_ext}' после вставки меток\")\n",
    "            \n",
    "            # Сохраняем обновлённый TXT файл (при этом JSON можно оставить без изменений или обновить по необходимости)\n",
    "            with open(txt_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(transcription.get(\"text\", \"\"))\n",
    "            print(f\"[INFO] TXT файл обновлён с метками: {txt_output_path}\")\n",
    "        else:\n",
    "            print(f\"[INFO] Папка с кадрами не найдена для видео '{video_name_no_ext}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187b32c4-17a8-499d-aec7-c63d645f6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_directory = '/content/test/input'\n",
    "whisper_json_directory = '/content/test/work/whisper_json'\n",
    "whisper_text_directory = '/content/test/work/whisper_text'\n",
    "extracted_frames_base = '/content/test/output/images'\n",
    "output_folder = '/content/test/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6877215-642f-4191-9b20-3e613b89a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этап 1: Вставка меток изображений в транскрипцию и обновление TXT-файла\n",
    "process_frame_markers(video_directory, whisper_json_directory, whisper_text_directory, extracted_frames_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83cac2-c694-49c4-96c3-817b110ff2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Этап 2: Составление конспекта из TXT и добавление mermaid схем\n",
    "process_and_generate_conspect(whisper_text_directory, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
