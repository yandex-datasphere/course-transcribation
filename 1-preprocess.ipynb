{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679351f4-d874-41e3-a37c-d80d0cbd4e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T08:36:42.682249Z",
     "iopub.status.busy": "2025-04-07T08:36:42.681315Z",
     "iopub.status.idle": "2025-04-07T08:36:48.120518Z",
     "shell.execute_reply": "2025-04-07T08:36:48.119655Z",
     "shell.execute_reply.started": "2025-04-07T08:36:42.682210Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentence_transformers in /home/jupyter/.local/lib/python3.10/site-packages (3.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sentence_transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/jupyter/.local/lib/python3.10/site-packages (from sentence_transformers) (0.26.5)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/jupyter/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter/.local/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->sentence_transformers) (3.25.2)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->sentence_transformers) (16.0.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.22.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/jupyter/.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d54c4c9a-a0a3-4c8c-b496-d71bfd580395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T08:36:48.122261Z",
     "iopub.status.busy": "2025-04-07T08:36:48.121744Z",
     "iopub.status.idle": "2025-04-07T08:37:26.962326Z",
     "shell.execute_reply": "2025-04-07T08:37:26.961400Z",
     "shell.execute_reply.started": "2025-04-07T08:36:48.122223Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:106: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2025-04-07 08:37:09.724730: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-07 08:37:11.308007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-04-07 08:37:15.924237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2712a60e-f1ee-4584-882c-dbf4e88349b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T08:37:26.965382Z",
     "iopub.status.busy": "2025-04-07T08:37:26.964135Z",
     "iopub.status.idle": "2025-04-07T08:37:27.221638Z",
     "shell.execute_reply": "2025-04-07T08:37:27.220788Z",
     "shell.execute_reply.started": "2025-04-07T08:37:26.965344Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Weights for metrics ---\n",
    "WEIGHT_TEXT = 0.1\n",
    "WEIGHT_DIFF = 0.6\n",
    "WEIGHT_SIMILARITY = 0.2\n",
    "WEIGHT_RECENCY = 0.05\n",
    "\n",
    "def text_quantity(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def frame_diff(frame1, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    return np.sum(cv2.absdiff(gray1, gray2)) / gray1.size\n",
    "\n",
    "def normalize_list(values):\n",
    "    min_v, max_v = min(values), max(values)\n",
    "    return [(v - min_v) / (max_v - min_v) if max_v > min_v else 0 for v in values]\n",
    "\n",
    "def standardize_list(values):\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    if std_val == 0:\n",
    "        return [0.5 for _ in values]\n",
    "    z_scores = [(v - mean_val) / std_val for v in values]\n",
    "    return [norm.cdf(z) for z in z_scores]\n",
    "\n",
    "def calculate_recency(candidates, selected_frames, interval_seconds):\n",
    "    # Вычисляем recency для каждого кандидата по хронологии\n",
    "    selected_timecodes = set(f['timecode'] for f in selected_frames)\n",
    "    sorted_candidates = sorted(candidates, key=lambda f: f['timecode'])\n",
    "    recency_vals = []\n",
    "    counter = 0\n",
    "    for frame in sorted_candidates:\n",
    "        if frame['timecode'] in selected_timecodes:\n",
    "            recency_vals.append(0.0)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            val = 0.1 + 0.2 * (counter - 1)\n",
    "            if val > 1.0:\n",
    "                val = 1.0\n",
    "            recency_vals.append(val)\n",
    "    return recency_vals\n",
    "\n",
    "def extract_key_frames(video_path, all_frames_dir, top_frames_dir, config_path, interval_seconds=10, top_n=5, max_iter=100):\n",
    "    # Инициализация easyocr и SentenceTransformer\n",
    "    reader = easyocr.Reader(['en', 'ru'], gpu=True)\n",
    "    embedder = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    total_duration = total_frames / fps\n",
    "\n",
    "    # Получаем размеры кадра из первого считанного кадра\n",
    "    ret, sample_frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Ошибка чтения видео\")\n",
    "        return\n",
    "    height, width = sample_frame.shape[:2]\n",
    "    # Сброс позиции для повторного чтения видео\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    # Используем полный кадр (координаты сохраняются для конфига)\n",
    "    x1, y1 = 0, 0\n",
    "    x2, y2 = width, height\n",
    "\n",
    "    prev_frames = []\n",
    "    all_embeddings = []\n",
    "    frame_candidates = []\n",
    "\n",
    "    frame_num = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_time = frame_num / fps\n",
    "        if current_time >= total_duration - interval_seconds:\n",
    "            break\n",
    "\n",
    "        # Здесь не производится обрезка: используется весь кадр\n",
    "        if frame_num % int(fps * interval_seconds) == 0 and frame_num != 0:\n",
    "            # Прогон через easyocr\n",
    "            text_results = reader.readtext(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY))\n",
    "            text = \" \".join([t[1] for t in text_results])\n",
    "            if len(text.strip()) >= 10:\n",
    "                current_embedding = embedder.encode(text)\n",
    "                diff_scores = [frame_diff(frame, pf) for pf in prev_frames] if prev_frames else [0]\n",
    "                avg_diff_score = np.mean(diff_scores)\n",
    "                text_qty = text_quantity(text)\n",
    "\n",
    "                if all_embeddings:\n",
    "                    sim_scores = [cosine_similarity([current_embedding], [emb])[0][0] for emb in all_embeddings]\n",
    "                    max_sim_score = max(sim_scores)\n",
    "                else:\n",
    "                    max_sim_score = 0\n",
    "                semantic_uniqueness = 1 - max_sim_score\n",
    "\n",
    "                frame_candidates.append({\n",
    "                    \"frame\": frame.copy(),\n",
    "                    \"text\": text,\n",
    "                    \"text_quantity\": text_qty,\n",
    "                    \"diff_score\": avg_diff_score,\n",
    "                    \"sim_score\": semantic_uniqueness,\n",
    "                    \"timecode\": current_time\n",
    "                })\n",
    "\n",
    "                prev_frames.append(frame.copy())\n",
    "                all_embeddings.append(current_embedding)\n",
    "                if len(prev_frames) > 2:\n",
    "                    prev_frames.pop(0)\n",
    "        frame_num += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # Нормализуем метрики\n",
    "    text_norm = normalize_list([f['text_quantity'] for f in frame_candidates])\n",
    "    diff_norm = normalize_list([f['diff_score'] for f in frame_candidates])\n",
    "    sim_norm = normalize_list([f['sim_score'] for f in frame_candidates])\n",
    "\n",
    "    for idx, frame in enumerate(frame_candidates):\n",
    "        frame['text_norm'] = text_norm[idx]\n",
    "        frame['diff_norm'] = diff_norm[idx]\n",
    "        frame['sim_norm'] = sim_norm[idx]\n",
    "        frame['recency_norm'] = 0\n",
    "\n",
    "    # Начальный выбор (без учета recency) по сумме первых трёх метрик\n",
    "    selected_frames = sorted(\n",
    "        frame_candidates,\n",
    "        key=lambda x: (WEIGHT_TEXT * x['text_norm'] +\n",
    "                       WEIGHT_DIFF * x['diff_norm'] +\n",
    "                       WEIGHT_SIMILARITY * x['sim_norm']),\n",
    "        reverse=True\n",
    "    )[:top_n]\n",
    "\n",
    "    # Итеративное улучшение выбора\n",
    "    for iteration in range(max_iter):\n",
    "        prev_selected = selected_frames.copy()\n",
    "        recency_norm = calculate_recency(frame_candidates, selected_frames, interval_seconds)\n",
    "        for idx, frame in enumerate(frame_candidates):\n",
    "            frame['recency_norm'] = recency_norm[idx]\n",
    "            frame['composite_score'] = (\n",
    "                WEIGHT_TEXT * frame['text_norm'] +\n",
    "                WEIGHT_DIFF * frame['diff_norm'] +\n",
    "                WEIGHT_SIMILARITY * frame['sim_norm'] +\n",
    "                WEIGHT_RECENCY * frame['recency_norm']\n",
    "            )\n",
    "        selected_frames = sorted(frame_candidates, key=lambda x: x['composite_score'], reverse=True)[:top_n]\n",
    "        if set(f['timecode'] for f in selected_frames) == set(f['timecode'] for f in prev_selected):\n",
    "            print(f\"Итерация стабилизировалась на {iteration+1}-й итерации.\")\n",
    "            break\n",
    "\n",
    "    # Визуализация составных метрик (необязательно)\n",
    "    plt.figure(figsize=(15, 7))\n",
    "    times = [f['timecode'] for f in frame_candidates]\n",
    "    bar_width = interval_seconds * 0.8\n",
    "    bottom = np.zeros(len(times))\n",
    "    plt.bar(times, [WEIGHT_TEXT * v for v in text_norm], width=bar_width, label='Text Quantity')\n",
    "    bottom += np.array([WEIGHT_TEXT * v for v in text_norm])\n",
    "    plt.bar(times, [WEIGHT_DIFF * v for v in diff_norm], width=bar_width, bottom=bottom, label='Frame Diff')\n",
    "    bottom += np.array([WEIGHT_DIFF * v for v in diff_norm])\n",
    "    plt.bar(times, [WEIGHT_SIMILARITY * v for v in sim_norm], width=bar_width, bottom=bottom, label='Semantic Uniqueness')\n",
    "    bottom += np.array([WEIGHT_SIMILARITY * v for v in sim_norm])\n",
    "    plt.bar(times, [WEIGHT_RECENCY * f['recency_norm'] for f in frame_candidates],\n",
    "            width=bar_width, bottom=bottom, label='Recency')\n",
    "    plt.title(\"Составные метрики по времени\")\n",
    "    plt.xlabel(\"Время (с)\")\n",
    "    plt.ylabel(\"Оценка\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    os.makedirs(all_frames_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(all_frames_dir, \"composite_score_components.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Сохранение всех обработанных кадров и их метрик в отдельной папке\n",
    "    all_frames_data = []\n",
    "    for idx, frame_info in enumerate(frame_candidates):\n",
    "        filename = f\"{int(round(frame_info['timecode']))}s_top_{idx+1}.jpg\"\n",
    "        output_path = os.path.join(all_frames_dir, filename)\n",
    "        cv2.imwrite(output_path, frame_info['frame'])\n",
    "        frame_info_copy = frame_info.copy()\n",
    "        # Удаляем изображение перед сохранением в JSON\n",
    "        frame_info_copy.pop('frame', None)\n",
    "        frame_info_copy['filename'] = filename\n",
    "        all_frames_data.append(frame_info_copy)\n",
    "\n",
    "    with open(os.path.join(all_frames_dir, \"all_frames_data.json\"), \"w\", encoding='utf-8') as json_file:\n",
    "        json.dump(all_frames_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # Сохранение топ-n кадров в отдельной директории\n",
    "    os.makedirs(top_frames_dir, exist_ok=True)\n",
    "    top_frames_data = []\n",
    "    for idx, frame_info in enumerate(selected_frames):\n",
    "        filename = f\"{int(round(frame_info['timecode']))}s_top_{idx+1}.jpg\"\n",
    "        output_path = os.path.join(top_frames_dir, filename)\n",
    "        cv2.imwrite(output_path, frame_info['frame'])\n",
    "        frame_info_copy = frame_info.copy()\n",
    "        frame_info_copy.pop('frame', None)\n",
    "        frame_info_copy['filename'] = filename\n",
    "        top_frames_data.append(frame_info_copy)\n",
    "\n",
    "    with open(os.path.join(top_frames_dir, \"top_frames_data.json\"), \"w\", encoding='utf-8') as json_file:\n",
    "        json.dump(top_frames_data, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # Сохранение конфигурационного файла с используемыми параметрами\n",
    "    config = {\n",
    "        \"weights\": {\n",
    "            \"WEIGHT_TEXT\": WEIGHT_TEXT,\n",
    "            \"WEIGHT_DIFF\": WEIGHT_DIFF,\n",
    "            \"WEIGHT_SIMILARITY\": WEIGHT_SIMILARITY,\n",
    "            \"WEIGHT_RECENCY\": WEIGHT_RECENCY\n",
    "        },\n",
    "        \"coordinates\": {\n",
    "            \"x1\": x1,\n",
    "            \"y1\": y1,\n",
    "            \"x2\": x2,\n",
    "            \"y2\": y2\n",
    "        }\n",
    "    }\n",
    "    with open(config_path, \"w\", encoding='utf-8') as json_file:\n",
    "        json.dump(config, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"\\nСохранено {len(frame_candidates)} обработанных кадров с метриками в {all_frames_dir}\")\n",
    "    print(f\"Сохранено топ-{top_n} кадров в {top_frames_dir}\")\n",
    "    print(f\"Конфигурация сохранена в {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5067afea-c6d4-4a33-939b-a2f47fa350b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T08:37:27.224424Z",
     "iopub.status.busy": "2025-04-07T08:37:27.222686Z",
     "iopub.status.idle": "2025-04-07T08:39:10.241884Z",
     "shell.execute_reply": "2025-04-07T08:39:10.241024Z",
     "shell.execute_reply.started": "2025-04-07T08:37:27.224384Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Сохранено 40 обработанных кадров с метриками в /home/jupyter/datasphere/s3/transcribation-project/test/work/all_images/WEEK_3_-_LEC_14\n",
      "Сохранено топ-10 кадров в /home/jupyter/datasphere/s3/transcribation-project/test/output/images/WEEK_3_-_LEC_14\n",
      "Конфигурация сохранена в /home/jupyter/datasphere/s3/transcribation-project/test/WEEK_3_-_LEC_14_config.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Запуск ---\n",
    "video_directory = '/home/jupyter/datasphere/s3/transcribation-project/test/input'\n",
    "all_frames_output_directory = '/home/jupyter/datasphere/s3/transcribation-project/test/work/all_images'\n",
    "top_frames_output_directory = '/home/jupyter/datasphere/s3/transcribation-project/test/output/images'\n",
    "config_directory = '/home/jupyter/datasphere/s3/transcribation-project/test'\n",
    "\n",
    "os.makedirs(all_frames_output_directory, exist_ok=True)\n",
    "os.makedirs(top_frames_output_directory, exist_ok=True)\n",
    "os.makedirs(config_directory, exist_ok=True)\n",
    "\n",
    "for video_file in os.listdir(video_directory):\n",
    "    if video_file.lower().endswith(('.mp4', '.avi', '.mkv')):\n",
    "        video_path = os.path.join(video_directory, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0].replace(' ', '_')  # Замена пробелов на '_'\n",
    "        \n",
    "        # Для каждого видео создаем свои директории для сохранения результатов\n",
    "        video_all_frames_dir = os.path.join(all_frames_output_directory, video_name)\n",
    "        video_top_frames_dir = os.path.join(top_frames_output_directory, video_name)\n",
    "        os.makedirs(video_all_frames_dir, exist_ok=True)\n",
    "        os.makedirs(video_top_frames_dir, exist_ok=True)\n",
    "        \n",
    "        # Путь для конфигурационного файла\n",
    "        config_path = os.path.join(config_directory, f\"{video_name}_config.json\")\n",
    "        \n",
    "        extract_key_frames(video_path, video_all_frames_dir, video_top_frames_dir, config_path, interval_seconds=10, top_n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e01741-7b36-4191-a024-2c7b85544a3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58cfbe31-15c5-4192-b63e-82ff73d18645",
   "metadata": {},
   "source": [
    "# Транскрипция видео с Whisper и вставка маркеров изображений\n",
    "\n",
    "Данный ноутбук выполняет следующие задачи:\n",
    "1. Проходит по всем видео в папке `video_directory` и транскрибирует их с помощью модели Whisper (base), получая JSON с таймкодами.\n",
    "2. Если для видео существует папка с извлечёнными кадрами в `extracted_frames_base` (имя папки совпадает с именем видео без расширения, где пробелы заменены на `_`), то для каждого изображения (например, `149s_top_6.jpg`) извлекается временная метка и ищется соответствующий сегмент транскрипции.\n",
    "3. В соответствующий сегмент вставляется маркер изображения в формате `⟪149s_top_6.jpg⟫` (маркер вставляется после последней точки предложения, если она есть).\n",
    "4. Итоговый JSON транскрипции сохраняется в папку `whisper_json`.\n",
    "5. Из JSON извлекается поле `text`, и сохраняется как текстовый файл (.txt) в папку `whisper_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e78bf78d-e0d4-4121-a667-6d4e67f14e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T07:54:37.842787Z",
     "iopub.status.busy": "2025-04-07T07:54:37.841944Z",
     "iopub.status.idle": "2025-04-07T07:54:39.624352Z",
     "shell.execute_reply": "2025-04-07T07:54:39.623700Z",
     "shell.execute_reply.started": "2025-04-07T07:54:37.842750Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import whisper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae6c12cb-a054-47b9-8d21-fb13e24a4727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T07:54:39.626479Z",
     "iopub.status.busy": "2025-04-07T07:54:39.625233Z",
     "iopub.status.idle": "2025-04-07T07:54:39.655473Z",
     "shell.execute_reply": "2025-04-07T07:54:39.654833Z",
     "shell.execute_reply.started": "2025-04-07T07:54:39.626444Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_videos_transcription(video_directory, whisper_json_directory, whisper_text_directory):\n",
    "    \"\"\"\n",
    "    Функция транскрипции:\n",
    "      1. Для каждого видео в video_directory, если итоговый TXT уже существует – пропускаем.\n",
    "      2. Если TXT отсутствует, проверяется наличие JSON:\n",
    "         - Если JSON существует, он загружается.\n",
    "         - Если JSON отсутствует, запускается транскрипция с Whisper (base) и результат сохраняется.\n",
    "      3. Итоговый текст формируется как объединение сегментов (без вставки меток) и сохраняется в TXT.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Загружаем модель Whisper (base)...\")\n",
    "    model = whisper.load_model(\"base\")\n",
    "    \n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if not video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            continue\n",
    "        \n",
    "        video_path = os.path.join(video_directory, video_file)\n",
    "        video_name_no_ext = os.path.splitext(video_file)[0]\n",
    "        video_name_clean = video_name_no_ext.replace(\" \", \"_\")\n",
    "        print(f\"[INFO] Обработка видео: {video_path}\")\n",
    "        \n",
    "        json_output_path = os.path.join(whisper_json_directory, video_name_clean + \".json\")\n",
    "        txt_output_path = os.path.join(whisper_text_directory, video_name_clean + \".txt\")\n",
    "        \n",
    "        # Если итоговый TXT уже существует, пропускаем обработку этого видео\n",
    "        if os.path.exists(txt_output_path):\n",
    "            print(f\"[INFO] TXT файл для видео '{video_name_no_ext}' уже существует ({txt_output_path}). Пропускаем обработку.\")\n",
    "            continue\n",
    "        \n",
    "        # Если JSON существует, загружаем его, иначе запускаем транскрипцию\n",
    "        if os.path.exists(json_output_path):\n",
    "            print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' уже существует. Загружаем JSON.\")\n",
    "            with open(json_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                transcription = json.load(f)\n",
    "        else:\n",
    "            print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' не найдена. Запускаем транскрипцию.\")\n",
    "            transcription = model.transcribe(video_path, task=\"transcribe\")\n",
    "            with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(transcription, f, ensure_ascii=False, indent=4)\n",
    "            print(f\"[INFO] JSON транскрипция сохранена: {json_output_path}\")\n",
    "        \n",
    "        # Формируем итоговый текст транскрипции как объединение сегментов (без маркеров)\n",
    "        if \"segments\" in transcription:\n",
    "            transcription[\"text\"] = \" \".join(seg[\"text\"] for seg in transcription[\"segments\"])\n",
    "            print(f\"[DEBUG] Итоговый текст сформирован. Длина текста: {len(transcription['text'])} символов\")\n",
    "        else:\n",
    "            print(f\"[WARN] Нет сегментов в транскрипции для видео '{video_name_no_ext}'\")\n",
    "        \n",
    "        # Сохраняем итоговый текст в TXT\n",
    "        with open(txt_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(transcription.get(\"text\", \"\"))\n",
    "        print(f\"[INFO] TXT файл сохранён: {txt_output_path}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b326c1-cfda-4100-9ea9-292b204f2d65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T07:54:39.659545Z",
     "iopub.status.busy": "2025-04-07T07:54:39.656386Z",
     "iopub.status.idle": "2025-04-07T07:54:39.717698Z",
     "shell.execute_reply": "2025-04-07T07:54:39.717065Z",
     "shell.execute_reply.started": "2025-04-07T07:54:39.659520Z"
    }
   },
   "outputs": [],
   "source": [
    "# def insert_frame_images(transcription, frames_dir):\n",
    "#     \"\"\"\n",
    "#     Для каждого файла кадра в папке frames_dir с именем вида \"149s_top_6.jpg\":\n",
    "#       - извлекает временную метку (например, 149),\n",
    "#       - определяет соответствующий сегмент транскрипции,\n",
    "#       - вставляет маркер изображения в формате \"⟪149s_top_6.jpg⟫\" после последней точки предложения.\n",
    "#     \"\"\"\n",
    "#     print(f\"[DEBUG] Обработка изображений из папки: {frames_dir}\")\n",
    "#     # Получаем список файлов изображений (поддерживаются форматы jpg и png)\n",
    "#     frame_files = [f for f in os.listdir(frames_dir) if f.lower().endswith(('.jpg', '.png'))]\n",
    "#     print(f\"[DEBUG] Найдено {len(frame_files)} файлов изображений: {frame_files}\")\n",
    "    \n",
    "#     # Создаем словарь: время кадра (float) -> имя файла\n",
    "#     frame_mapping = {}\n",
    "#     for filename in frame_files:\n",
    "#         match = re.match(r'(\\d+)s', filename)\n",
    "#         if match:\n",
    "#             timestamp = float(match.group(1))\n",
    "#             frame_mapping[timestamp] = filename\n",
    "#             print(f\"[DEBUG] Файл {filename}: timestamp {timestamp}\")\n",
    "#         else:\n",
    "#             print(f\"[DEBUG] Файл {filename} не соответствует ожидаемому формату\")\n",
    "    \n",
    "#     # Обрабатываем каждый кадр: ищем соответствующий сегмент транскрипции\n",
    "#     for frame_time, image_file in frame_mapping.items():\n",
    "#         segment_found = None\n",
    "#         for seg in transcription.get(\"segments\", []):\n",
    "#             if seg[\"start\"] <= frame_time <= seg[\"end\"]:\n",
    "#                 segment_found = seg\n",
    "#                 print(f\"[DEBUG] Timestamp {frame_time} найден в сегменте {seg.get('id', 'N/A')} (диапазон {seg['start']} - {seg['end']})\")\n",
    "#                 break\n",
    "#         if not segment_found and transcription.get(\"segments\", []):\n",
    "#             segment_found = min(transcription[\"segments\"], key=lambda seg: abs(seg[\"start\"] - frame_time))\n",
    "#             print(f\"[DEBUG] Timestamp {frame_time} не попадает ни в один сегмент, выбран ближайший сегмент {segment_found.get('id', 'N/A')} (диапазон {segment_found['start']} - {segment_found['end']})\")\n",
    "#         if segment_found:\n",
    "#             marker = f\" ⟪{image_file}⟫\"\n",
    "#             seg_text = segment_found.get(\"text\", \"\")\n",
    "#             last_dot = seg_text.rfind('.')\n",
    "#             if last_dot != -1:\n",
    "#                 new_text = seg_text[:last_dot+1] + marker + seg_text[last_dot+1:]\n",
    "#             else:\n",
    "#                 new_text = seg_text + marker\n",
    "#             print(f\"[DEBUG] Вставка маркера {marker} в сегмент {segment_found.get('id', 'N/A')}\")\n",
    "#             segment_found[\"text\"] = new_text\n",
    "#         else:\n",
    "#             print(f\"[DEBUG] Не найден сегмент для файла {image_file} с timestamp {frame_time}\")\n",
    "#     return transcription\n",
    "\n",
    "\n",
    "# def process_frame_markers(video_directory, whisper_json_directory, whisper_text_directory, extracted_frames_base):\n",
    "#     \"\"\"\n",
    "#     Функция вставки меток:\n",
    "#       1. Для каждого видео в video_directory проверяется наличие JSON транскрипции и соответствующего TXT.\n",
    "#       2. Поиск папки с извлечёнными кадрами (варианты имени – оригинальное, с заменой пробелов и наоборот).\n",
    "#       3. Если папка найдена, загружается JSON, выполняется вставка маркеров через insert_frame_images,\n",
    "#          итоговый текст (объединение сегментов) формируется заново и сохраняется в TXT.\n",
    "#     \"\"\"\n",
    "#     for video_file in os.listdir(video_directory):\n",
    "#         if not video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "#             continue\n",
    "        \n",
    "#         video_name_no_ext = os.path.splitext(video_file)[0]\n",
    "#         video_name_clean = video_name_no_ext.replace(\" \", \"_\")\n",
    "#         json_output_path = os.path.join(whisper_json_directory, video_name_clean + \".json\")\n",
    "#         txt_output_path = os.path.join(whisper_text_directory, video_name_clean + \".txt\")\n",
    "        \n",
    "#         # Если JSON или TXT не существует, пропускаем видео (так как транскрипция должна быть выполнена первой)\n",
    "#         if not os.path.exists(json_output_path):\n",
    "#             print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' не найдена. Пропускаем вставку маркеров.\")\n",
    "#             continue\n",
    "#         if not os.path.exists(txt_output_path):\n",
    "#             print(f\"[INFO] TXT файл для видео '{video_name_no_ext}' не найден. Пропускаем вставку маркеров.\")\n",
    "#             continue\n",
    "        \n",
    "#         # Загружаем JSON транскрипции\n",
    "#         with open(json_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "#             transcription = json.load(f)\n",
    "        \n",
    "#         # Поиск папки с извлечёнными кадрами: варианты имени – оригинальное, с заменой пробелов и наоборот\n",
    "#         folder_options = {\n",
    "#             video_name_no_ext,\n",
    "#             video_name_no_ext.replace(\" \", \"_\"),\n",
    "#             video_name_no_ext.replace(\"_\", \" \")\n",
    "#         }\n",
    "#         print(f\"[DEBUG] Варианты имени папки для кадров: {folder_options}\")\n",
    "#         frames_dir = None\n",
    "#         for folder in folder_options:\n",
    "#             potential_dir = os.path.join(extracted_frames_base, folder)\n",
    "#             print(f\"[DEBUG] Проверка папки: {potential_dir}\")\n",
    "#             if os.path.exists(potential_dir):\n",
    "#                 frames_dir = potential_dir\n",
    "#                 print(f\"[INFO] Папка с кадрами найдена: {frames_dir}\")\n",
    "#                 break\n",
    "        \n",
    "#         if frames_dir:\n",
    "#             # Выполняем вставку маркеров в транскрипцию\n",
    "#             transcription = insert_frame_images(transcription, frames_dir)\n",
    "#             # Формируем новый итоговый текст (объединение сегментов с маркерами)\n",
    "#             if \"segments\" in transcription:\n",
    "#                 transcription[\"text\"] = \" \".join(seg[\"text\"] for seg in transcription[\"segments\"])\n",
    "#                 print(f\"[DEBUG] Итоговый текст с метками сформирован. Длина текста: {len(transcription['text'])} символов\")\n",
    "#             else:\n",
    "#                 print(f\"[WARN] Нет сегментов в транскрипции для видео '{video_name_no_ext}' после вставки меток\")\n",
    "            \n",
    "#             # Сохраняем обновлённый TXT файл (при этом JSON можно оставить без изменений или обновить по необходимости)\n",
    "#             with open(txt_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#                 f.write(transcription.get(\"text\", \"\"))\n",
    "#             print(f\"[INFO] TXT файл обновлён с метками: {txt_output_path}\")\n",
    "#         else:\n",
    "#             print(f\"[INFO] Папка с кадрами не найдена для видео '{video_name_no_ext}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73d405ed-0df9-4540-9bda-0135034b2806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-07T07:54:39.720220Z",
     "iopub.status.busy": "2025-04-07T07:54:39.719413Z",
     "iopub.status.idle": "2025-04-07T07:55:01.128827Z",
     "shell.execute_reply": "2025-04-07T07:55:01.128152Z",
     "shell.execute_reply.started": "2025-04-07T07:54:39.720192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Загружаем модель Whisper (base)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:05<00:00, 28.0MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Обработка видео: /home/jupyter/datasphere/s3/transcribation-project/test/input/WEEK 3 - LEC 14.mp4\n",
      "[INFO] JSON транскрипция для видео 'WEEK 3 - LEC 14' не найдена. Запускаем транскрипцию.\n",
      "[INFO] JSON транскрипция сохранена: /home/jupyter/datasphere/s3/transcribation-project/test/work/whisper_json/WEEK_3_-_LEC_14.json\n",
      "[DEBUG] Итоговый текст сформирован. Длина текста: 5448 символов\n",
      "[INFO] TXT файл сохранён: /home/jupyter/datasphere/s3/transcribation-project/test/work/whisper_text/WEEK_3_-_LEC_14.txt\n"
     ]
    }
   ],
   "source": [
    "video_directory = '/home/jupyter/datasphere/s3/transcribation-project/test/input'\n",
    "whisper_json_directory = '/home/jupyter/datasphere/s3/transcribation-project/test/work/whisper_json'\n",
    "whisper_text_directory = '/home/jupyter/datasphere/s3/transcribation-project/test/work/whisper_text'\n",
    "extracted_frames_base = '/home/jupyter/datasphere/s3/transcribation-project/test/output/images'\n",
    "\n",
    "os.makedirs(whisper_json_directory, exist_ok=True)\n",
    "os.makedirs(whisper_text_directory, exist_ok=True)\n",
    "\n",
    "# Этап 1: Транскрипция видео и сохранение итогового TXT без меток\n",
    "process_videos_transcription(video_directory, whisper_json_directory, whisper_text_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368ff9d0-3353-4add-bc67-b109846f538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Этап 2: Вставка меток изображений в транскрипцию и обновление TXT-файла\n",
    "# process_frame_markers(video_directory, whisper_json_directory, whisper_text_directory, extracted_frames_base)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99567183-c33e-4c7b-b185-6832a5c7fefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e14591-3352-4daf-bf62-b2a1ce024346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87394c63-3fd6-49af-a609-f0fb9816dbda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63432286-4022-4514-9a79-de299724ffc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
