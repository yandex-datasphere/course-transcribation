{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "679351f4-d874-41e3-a37c-d80d0cbd4e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:22:09.514899Z",
     "iopub.status.busy": "2025-04-23T18:22:09.513184Z",
     "iopub.status.idle": "2025-04-23T18:22:50.866056Z",
     "shell.execute_reply": "2025-04-23T18:22:50.865154Z",
     "shell.execute_reply.started": "2025-04-23T18:22:09.514857Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (11.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\илья\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\илья\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\илья\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: easyocr in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: torch in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (2.6.0+cu118)\n",
      "Requirement already satisfied: torchvision>=0.5 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.21.0+cu118)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (4.11.0.86)\n",
      "Requirement already satisfied: scipy in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.15.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (2.2.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (11.2.1)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (2.1.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.11.1.4)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\илья\\appdata\\roaming\\python\\python313\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->easyocr) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->easyocr) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->easyocr) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->easyocr) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch->easyocr) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\илья\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch->easyocr) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai-whisper in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (20240930)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (10.6.0)\n",
      "Requirement already satisfied: numba in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (0.61.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (2.2.4)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: torch in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (2.6.0+cu118)\n",
      "Requirement already satisfied: tqdm in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from numba->openai-whisper) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\илья\\appdata\\roaming\\python\\python313\\site-packages (from tqdm->openai-whisper) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\илья\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Устанавливаем все необходимые библиотеки для работы ноутбука\n",
    "%pip install --upgrade pip\n",
    "\n",
    "# Базовые числовые и научные пакеты\n",
    "%pip install numpy opencv-python matplotlib scipy scikit-learn pillow\n",
    "\n",
    "# PyTorch (CPU-только)\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "\n",
    "# OCR и эмбеддинги\n",
    "%pip install easyocr sentence-transformers\n",
    "\n",
    "# Whisper от OpenAI\n",
    "%pip install openai-whisper\n",
    "\n",
    "# Установка транслитератора\n",
    "%pip install Unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509af048-1cb3-42f1-8632-eafc462bcc5a",
   "metadata": {},
   "source": [
    "При необходимости перезапустите ядро (Kernel → Restart) и только потом выполняйте остальные ячейки с импортами и вашим кодом. Так вы гарантированно избежите «ModuleNotFoundError» и подобных ошибок на чистой системе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54c4c9a-a0a3-4c8c-b496-d71bfd580395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:27:50.050496Z",
     "iopub.status.busy": "2025-04-23T18:27:50.049562Z",
     "iopub.status.idle": "2025-04-23T18:27:50.095840Z",
     "shell.execute_reply": "2025-04-23T18:27:50.095016Z",
     "shell.execute_reply.started": "2025-04-23T18:27:50.050453Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Илья\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import easyocr\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.stats import norm\n",
    "import unidecode from unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "535ccc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.float32):\n",
    "            return float(obj)\n",
    "        return super().default(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2712a60e-f1ee-4584-882c-dbf4e88349b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:46:00.626300Z",
     "iopub.status.busy": "2025-04-23T18:46:00.624785Z",
     "iopub.status.idle": "2025-04-23T18:46:00.665537Z",
     "shell.execute_reply": "2025-04-23T18:46:00.664672Z",
     "shell.execute_reply.started": "2025-04-23T18:46:00.626253Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_safe_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    1) Транслитерирует Юникод в ASCII\n",
    "    2) Заменяет пробелы на '_'\n",
    "    3) Удаляет из строки всё, кроме A–Z, a–z, 0–9, '_' и '-'\n",
    "    \"\"\"\n",
    "    ascii_name = unidecode(name)            # e.g. \"Akadem. gramotnost' - W6_L3\"\n",
    "    ascii_name = ascii_name.replace(\" \", \"_\")# \"Akadem._gramotnost'_-_W6_L3\"\n",
    "    # удаляем точки, апострофы и прочие посторонние символы\n",
    "    safe = re.sub(r\"[^A-Za-z0-9_\\-]\", \"\", ascii_name)\n",
    "    return safe\n",
    "\n",
    "def text_quantity(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def frame_diff(frame1, frame2):\n",
    "    gray1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "    return np.sum(cv2.absdiff(gray1, gray2)) / gray1.size\n",
    "\n",
    "def normalize_list(values):\n",
    "    min_v, max_v = min(values), max(values)\n",
    "    return [(v - min_v) / (max_v - min_v) if max_v > min_v else 0 for v in values]\n",
    "\n",
    "def standardize_list(values):\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    if std_val == 0:\n",
    "        return [0.5 for _ in values]\n",
    "    z_scores = [(v - mean_val) / std_val for v in values]\n",
    "    return [norm.cdf(z) for z in z_scores]\n",
    "\n",
    "def calculate_recency(candidates, selected_frames, interval_seconds):\n",
    "    # Вычисляем recency для каждого кандидата по хронологии\n",
    "    selected_timecodes = set(f['timecode'] for f in selected_frames)\n",
    "    sorted_candidates = sorted(candidates, key=lambda f: f['timecode'])\n",
    "    recency_vals = []\n",
    "    counter = 0\n",
    "    for frame in sorted_candidates:\n",
    "        if frame['timecode'] in selected_timecodes:\n",
    "            recency_vals.append(0.0)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            val = 0.1 + 0.2 * (counter - 1)\n",
    "            if val > 1.0:\n",
    "                val = 1.0\n",
    "            recency_vals.append(val)\n",
    "    return recency_vals\n",
    "\n",
    "def extract_key_frames(\n",
    "    video_path: str,\n",
    "    all_frames_dir: str,\n",
    "    top_frames_dir: str,\n",
    "    coords_pct: dict,\n",
    "    weight_text: float,\n",
    "    weight_diff: float,\n",
    "    weight_similarity: float,\n",
    "    weight_recency: float,\n",
    "    interval_seconds: float = 10.0,\n",
    "    top_n: int = 5,\n",
    "    max_iter: int = 100\n",
    "):\n",
    "    \"\"\"\n",
    "    Извлечение ключевых кадров из видео с итеративным учётом recency.\n",
    "    \n",
    "    Параметры:\n",
    "      video_path          – путь к видеофайлу;\n",
    "      all_frames_dir      – папка для всех кадров и метрик;\n",
    "      top_frames_dir      – папка для сохранения итоговых top_n кадров;\n",
    "      coords_pct          – словарь процентных координат {'x1', 'y1', 'x2', 'y2'} в диапазоне [0,1];\n",
    "      weight_text         – вес текстовой метрики;\n",
    "      weight_diff         – вес diff-метрики;\n",
    "      weight_similarity   – вес семантической метрики;\n",
    "      weight_recency      – вес recency-метрики;\n",
    "      interval_seconds    – интервал между анализируемыми кадрами (сек);\n",
    "      top_n               – число кадров в итоговом наборе;\n",
    "      max_iter            – макс. число итераций для уточнения выбора.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import cv2\n",
    "    import json\n",
    "    import numpy as np\n",
    "    import easyocr\n",
    "    from scipy.stats import norm\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # 1) Инициализация OCR и эмбеддера\n",
    "    reader = easyocr.Reader(['en', 'ru'], gpu=True)\n",
    "    embedder = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
    "    emb_dim = embedder.get_sentence_embedding_dimension()\n",
    "\n",
    "    # 2) Открываем видео и узнаём базовые величины\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) or 1.0\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)\n",
    "    duration = total_frames / fps if fps > 0 else 0.0\n",
    "\n",
    "    # 3) Читаем первый кадр для размеров\n",
    "    ret, frame0 = cap.read()\n",
    "    if not ret:\n",
    "        print(f\"[ERROR] Не удалось открыть видео {video_path}\")\n",
    "        cap.release()\n",
    "        return\n",
    "    h, w = frame0.shape[:2]\n",
    "    x1 = int(coords_pct[\"x1\"] * w);  y1 = int(coords_pct[\"y1\"] * h)\n",
    "    x2 = int(coords_pct[\"x2\"] * w);  y2 = int(coords_pct[\"y2\"] * h)\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "    # 4) Собираем кандидатов\n",
    "    candidates = []\n",
    "    prev_frames = []\n",
    "    all_embs    = []\n",
    "    frame_idx   = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame_idx / fps >= duration - interval_seconds:\n",
    "            break\n",
    "\n",
    "        if frame_idx % int(fps * interval_seconds) == 0 and frame_idx != 0:\n",
    "            crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # текстовая метрика\n",
    "            txts = reader.readtext(crop)\n",
    "            text = \" \".join([t[1] for t in txts])\n",
    "            t_qty = len(text.split())\n",
    "\n",
    "            # diff-метрика\n",
    "            if prev_frames:\n",
    "                gray_new = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "                gray_old = cv2.cvtColor(prev_frames[-1], cv2.COLOR_BGR2GRAY)\n",
    "                t_diff = float(np.sum(cv2.absdiff(gray_new, gray_old))) / gray_new.size\n",
    "            else:\n",
    "                t_diff = 0.0\n",
    "\n",
    "            # семантическая уникальность\n",
    "            if text.strip():\n",
    "                emb = embedder.encode(text)\n",
    "            else:\n",
    "                emb = np.zeros(emb_dim, dtype=float)\n",
    "            if all_embs:\n",
    "                sims = [cosine_similarity([emb], [e])[0][0] for e in all_embs]\n",
    "                t_sim = 1.0 - max(sims)\n",
    "            else:\n",
    "                t_sim = 1.0\n",
    "\n",
    "            candidates.append({\n",
    "                'frame':      crop.copy(),\n",
    "                'timecode':   frame_idx / fps,\n",
    "                'text_qty':   t_qty,\n",
    "                'diff_score': t_diff,\n",
    "                'sim_score':  t_sim,\n",
    "                'rec_norm':   0.0\n",
    "            })\n",
    "            prev_frames.append(crop.copy())\n",
    "            all_embs.append(emb)\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # 5) Нормализация метрик\n",
    "    def normalize(vs):\n",
    "        arr = np.array(vs, float)\n",
    "        return (arr - arr.min()) / (arr.max() - arr.min()) if arr.max() > arr.min() else np.ones_like(arr)\n",
    "\n",
    "    text_norm = normalize([c['text_qty']   for c in candidates])\n",
    "    diff_norm = normalize([c['diff_score'] for c in candidates])\n",
    "    sim_norm  = normalize([c['sim_score']  for c in candidates])\n",
    "\n",
    "    for i, c in enumerate(candidates):\n",
    "        c['text_n'] = text_norm[i]\n",
    "        c['diff_n'] = diff_norm[i]\n",
    "        c['sim_n']  = sim_norm[i]\n",
    "\n",
    "    # 6) Начальный отбор\n",
    "    selected = sorted(\n",
    "        candidates,\n",
    "        key=lambda c: (weight_text * c['text_n'] +\n",
    "                       weight_diff * c['diff_n'] +\n",
    "                       weight_similarity * c['sim_n']),\n",
    "        reverse=True\n",
    "    )[:top_n]\n",
    "\n",
    "    # 7) Помощник для recency\n",
    "    def calc_recency(cands, sel):\n",
    "        times_sel = {int(round(f['timecode'])) for f in sel}\n",
    "        sorted_c = sorted(cands, key=lambda x: x['timecode'])\n",
    "        recs, cnt = [], 0\n",
    "        for f in sorted_c:\n",
    "            t = int(round(f['timecode']))\n",
    "            if t in times_sel:\n",
    "                recs.append(0.0); cnt = 0\n",
    "            else:\n",
    "                cnt += 1\n",
    "                recs.append(min(1.0, 0.1 + 0.2*(cnt-1)))\n",
    "        return recs\n",
    "\n",
    "    # 8) Итеративное уточнение composite-score\n",
    "    for _ in range(max_iter):\n",
    "        prev_set = {int(round(f['timecode'])) for f in selected}\n",
    "        recs = calc_recency(candidates, selected)\n",
    "        for i, c in enumerate(candidates):\n",
    "            c['rec_norm'] = recs[i]\n",
    "            c['comp'] = (\n",
    "                weight_text       * c['text_n'] +\n",
    "                weight_diff       * c['diff_n'] +\n",
    "                weight_similarity * c['sim_n'] +\n",
    "                weight_recency    * c['rec_norm']\n",
    "            )\n",
    "        selected = sorted(candidates, key=lambda x: x['comp'], reverse=True)[:top_n]\n",
    "        if prev_set == {int(round(f['timecode'])) for f in selected}:\n",
    "            break\n",
    "\n",
    "    # 9) (опционально) график\n",
    "    times = [c['timecode'] for c in candidates]\n",
    "    w = interval_seconds * 0.8\n",
    "    plt.figure(figsize=(12,6))\n",
    "    bottom = np.zeros(len(times))\n",
    "    for wt, arr, lbl in [\n",
    "      (weight_text, text_norm, 'Text'),\n",
    "      (weight_diff, diff_norm, 'Diff'),\n",
    "      (weight_similarity, sim_norm, 'Sim'),\n",
    "      (weight_recency, [c['rec_norm'] for c in candidates], 'Rec')\n",
    "    ]:\n",
    "        vals = wt * np.array(arr)\n",
    "        plt.bar(times, vals, width=w, bottom=bottom, label=lbl)\n",
    "        bottom += vals\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Score components\")\n",
    "    plt.legend(); plt.grid(True)\n",
    "    os.makedirs(all_frames_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(all_frames_dir, \"composite_score_components.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # 10) Сохранение всех кадров\n",
    "    os.makedirs(all_frames_dir, exist_ok=True)\n",
    "    all_data = []\n",
    "    for c in candidates:\n",
    "        tc = int(round(c['timecode']))\n",
    "        fname = f\"{tc:06d}.jpg\"\n",
    "        cv2.imwrite(os.path.join(all_frames_dir, fname), c['frame'])\n",
    "        info = {k: v for k, v in c.items() if k != 'frame'}\n",
    "        info['filename'] = fname\n",
    "        all_data.append(info)\n",
    "    with open(os.path.join(all_frames_dir, \"all_frames_data.json\"), \"w\", encoding=\"utf-8\") as jf:\n",
    "        json.dump(all_data, jf, cls=NumpyEncoder, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # 11) Сохранение top-n\n",
    "    os.makedirs(top_frames_dir, exist_ok=True)\n",
    "    top_data = []\n",
    "    for idx, c in enumerate(selected, start=1):\n",
    "        tc = int(round(c['timecode']))\n",
    "        fname = f\"{tc:06d}s_top_{idx}.jpg\"\n",
    "        cv2.imwrite(os.path.join(top_frames_dir, fname), c['frame'])\n",
    "        info = {k: v for k, v in c.items() if k != 'frame'}\n",
    "        info['filename'] = fname\n",
    "        top_data.append(info)\n",
    "    with open(os.path.join(top_frames_dir, \"top_frames_data.json\"), \"w\", encoding=\"utf-8\") as jf:\n",
    "        json.dump(top_data, jf, cls=NumpyEncoder, ensure_ascii=False, indent=4)\n",
    "\n",
    "    print(f\"\\nОбработано {len(candidates)} кадров → {all_frames_dir}\")\n",
    "    print(f\"Сохранено top-{top_n} кадров → {top_frames_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b178c234-c1b8-4e33-b270-10ce7c0ec444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:46:01.132281Z",
     "iopub.status.busy": "2025-04-23T18:46:01.131152Z",
     "iopub.status.idle": "2025-04-23T18:46:01.148399Z",
     "shell.execute_reply": "2025-04-23T18:46:01.147615Z",
     "shell.execute_reply.started": "2025-04-23T18:46:01.132232Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Загружаем конфигурацию из D:\\local\\config.json\n"
     ]
    }
   ],
   "source": [
    "import os, json\n",
    "from pathlib import Path\n",
    "\n",
    "# ——— Определяем местоположение ноутбука — обычно это рабочая папка Jupyter\n",
    "notebook_dir = Path().resolve()\n",
    "config_path  = notebook_dir / \"config.json\"\n",
    "\n",
    "# ——— Если нет — создаём с шаблоном (с процентными координатами)\n",
    "if not config_path.exists():\n",
    "    default_config = {\n",
    "      \"base_directory\": str(notebook_dir),\n",
    "      \"number_video_images\": 10,\n",
    "      \"weights\": {\n",
    "        \"WEIGHT_TEXT\":       0.1,\n",
    "        \"WEIGHT_DIFF\":       0.6,\n",
    "        \"WEIGHT_SIMILARITY\": 0.2,\n",
    "        \"WEIGHT_RECENCY\":    0.05\n",
    "      },\n",
    "      \"coordinates_pct\": {\n",
    "        \"x1\": 0.0,   # лево\n",
    "        \"y1\": 0.0,   # верх\n",
    "        \"x2\": 1.0,   # право\n",
    "        \"y2\": 1.0    # низ\n",
    "      }\n",
    "    }\n",
    "    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(default_config, f, cls=NumpyEncoder, ensure_ascii=False, indent=4)\n",
    "    print(f\"[INFO] Создан файл конфигурации: {config_path}\")\n",
    "else:\n",
    "    print(f\"[INFO] Загружаем конфигурацию из {config_path}\")\n",
    "\n",
    "# ——— Читаем конфиг\n",
    "with open(config_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af2ebb2-d0c5-4726-9318-a70543dbf9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:46:02.377355Z",
     "iopub.status.busy": "2025-04-23T18:46:02.376361Z",
     "iopub.status.idle": "2025-04-23T18:46:02.960066Z",
     "shell.execute_reply": "2025-04-23T18:46:02.959092Z",
     "shell.execute_reply.started": "2025-04-23T18:46:02.377312Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ——— Подтягиваем все параметры\n",
    "BASE_DIR             = Path(cfg[\"base_directory\"])\n",
    "NUMBER_VIDEO_IMAGES  = cfg[\"number_video_images\"]\n",
    "WEIGHT_TEXT          = cfg[\"weights\"][\"WEIGHT_TEXT\"]\n",
    "WEIGHT_DIFF          = cfg[\"weights\"][\"WEIGHT_DIFF\"]\n",
    "WEIGHT_SIMILARITY    = cfg[\"weights\"][\"WEIGHT_SIMILARITY\"]\n",
    "WEIGHT_RECENCY       = cfg[\"weights\"][\"WEIGHT_RECENCY\"]\n",
    "\n",
    "# ——— Процентные координаты (0.0–1.0)\n",
    "coords_pct = cfg[\"coordinates_pct\"]\n",
    "# сами пиксели будем вычислять уже внутрь функции, когда знаем ширину/высоту кадра\n",
    "\n",
    "# ——— Формируем нужные папки внутри BASE_DIR\n",
    "video_directory             = BASE_DIR / \"input\"\n",
    "all_frames_output_directory = BASE_DIR / \"work\"  / \"all_images\"\n",
    "top_frames_output_directory = BASE_DIR / \"output\"/ \"images\"\n",
    "\n",
    "# ——— Создадим их, если ещё нет\n",
    "os.makedirs(video_directory,             exist_ok=True)\n",
    "os.makedirs(all_frames_output_directory, exist_ok=True)\n",
    "os.makedirs(top_frames_output_directory, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5067afea-c6d4-4a33-939b-a2f47fa350b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T18:46:03.989967Z",
     "iopub.status.busy": "2025-04-23T18:46:03.989366Z",
     "iopub.status.idle": "2025-04-23T18:48:36.956592Z",
     "shell.execute_reply": "2025-04-23T18:48:36.955753Z",
     "shell.execute_reply.started": "2025-04-23T18:46:03.989924Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for video_file in os.listdir(video_directory):\n",
    "    if video_file.lower().endswith(('.mp4', '.avi', '.mkv')):\n",
    "        video_path = Path(video_directory) / video_file\n",
    "        raw_name   = video_path.stem\n",
    "        video_name = make_safe_name(raw_name)\n",
    "\n",
    "        video_all_frames_dir = Path(all_frames_output_directory) / video_name\n",
    "        video_top_frames_dir = Path(top_frames_output_directory) / video_name\n",
    "        os.makedirs(video_all_frames_dir, exist_ok=True)\n",
    "        os.makedirs(video_top_frames_dir, exist_ok=True)\n",
    "\n",
    "        extract_key_frames(\n",
    "            str(video_path),\n",
    "            str(video_all_frames_dir),\n",
    "            str(video_top_frames_dir),\n",
    "            coords_pct,\n",
    "            WEIGHT_TEXT,\n",
    "            WEIGHT_DIFF,\n",
    "            WEIGHT_SIMILARITY,\n",
    "            WEIGHT_RECENCY,\n",
    "            interval_seconds=10,\n",
    "            top_n=NUMBER_VIDEO_IMAGES,\n",
    "            max_iter=100\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e78bf78d-e0d4-4121-a667-6d4e67f14e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T22:04:59.309909Z",
     "iopub.status.busy": "2025-04-09T22:04:59.309166Z",
     "iopub.status.idle": "2025-04-09T22:05:01.081101Z",
     "shell.execute_reply": "2025-04-09T22:05:01.080356Z",
     "shell.execute_reply.started": "2025-04-09T22:04:59.309882Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import whisper\n",
    "\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae6c12cb-a054-47b9-8d21-fb13e24a4727",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T22:05:01.083830Z",
     "iopub.status.busy": "2025-04-09T22:05:01.082625Z",
     "iopub.status.idle": "2025-04-09T22:05:01.110766Z",
     "shell.execute_reply": "2025-04-09T22:05:01.110034Z",
     "shell.execute_reply.started": "2025-04-09T22:05:01.083788Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_videos_transcription(video_directory, whisper_json_directory, whisper_text_directory):\n",
    "    \"\"\"\n",
    "    Функция транскрипции:\n",
    "      1. Для каждого видео в video_directory, если итоговый TXT уже существует – пропускаем.\n",
    "      2. Если TXT отсутствует, проверяется наличие JSON:\n",
    "         - Если JSON существует, он загружается.\n",
    "         - Если JSON отсутствует, запускается транскрипция с Whisper (base) и результат сохраняется.\n",
    "      3. Итоговый текст формируется как объединение сегментов (без вставки меток) и сохраняется в TXT.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Загружаем модель Whisper (base)...\")\n",
    "    model = whisper.load_model(\"base\")\n",
    "    \n",
    "    for video_file in os.listdir(video_directory):\n",
    "        if not video_file.lower().endswith(('.mp4', '.avi', '.mov', '.mkv')):\n",
    "            continue\n",
    "        \n",
    "        video_path = os.path.join(video_directory, video_file)\n",
    "        video_name_no_ext = os.path.splitext(video_file)[0]\n",
    "        video_name_clean = video_name_no_ext.replace(\" \", \"_\")\n",
    "        \n",
    "        print(f\"[INFO] Обработка видео: {video_path}\")\n",
    "        \n",
    "        json_output_path = os.path.join(whisper_json_directory, video_name_clean + \".json\")\n",
    "        txt_output_path = os.path.join(whisper_text_directory, video_name_clean + \".txt\")\n",
    "        \n",
    "        # Если итоговый TXT уже существует, пропускаем обработку этого видео\n",
    "        if os.path.exists(txt_output_path):\n",
    "            print(f\"[INFO] TXT файл для видео '{video_name_no_ext}' уже существует ({txt_output_path}). Пропускаем обработку.\")\n",
    "            continue\n",
    "        \n",
    "        # Если JSON существует, загружаем его, иначе запускаем транскрипцию\n",
    "        if os.path.exists(json_output_path):\n",
    "            print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' уже существует. Загружаем JSON.\")\n",
    "            with open(json_output_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                transcription = json.load(f)\n",
    "        else:\n",
    "            print(f\"[INFO] JSON транскрипция для видео '{video_name_no_ext}' не найдена. Запускаем транскрипцию.\")\n",
    "            transcription = model.transcribe(video_path, task=\"transcribe\")\n",
    "            with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(transcription, f, cls=NumpyEncoder, ensure_ascii=False, indent=4)\n",
    "            print(f\"[INFO] JSON транскрипция сохранена: {json_output_path}\")\n",
    "        \n",
    "        # Формируем итоговый текст транскрипции как объединение сегментов (без маркеров)\n",
    "        if \"segments\" in transcription:\n",
    "            transcription[\"text\"] = \" \".join(seg[\"text\"] for seg in transcription[\"segments\"])\n",
    "            print(f\"[DEBUG] Итоговый текст сформирован. Длина текста: {len(transcription['text'])} символов\")\n",
    "        else:\n",
    "            print(f\"[WARN] Нет сегментов в транскрипции для видео '{video_name_no_ext}'\")\n",
    "        \n",
    "        # Сохраняем итоговый текст в TXT\n",
    "        with open(txt_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(transcription.get(\"text\", \"\"))\n",
    "        print(f\"[INFO] TXT файл сохранён: {txt_output_path}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d405ed-0df9-4540-9bda-0135034b2806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T22:05:01.272442Z",
     "iopub.status.busy": "2025-04-09T22:05:01.271655Z",
     "iopub.status.idle": "2025-04-09T22:05:41.315945Z",
     "shell.execute_reply": "2025-04-09T22:05:41.315113Z",
     "shell.execute_reply.started": "2025-04-09T22:05:01.272412Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Загружаем модель Whisper (base)...\n",
      "[INFO] Обработка видео: D:\\local\\input\\W1_L1 (DL_1_1).mp4\n",
      "[INFO] JSON транскрипция для видео 'W1_L1 (DL_1_1)' не найдена. Запускаем транскрипцию.\n",
      "[INFO] JSON транскрипция сохранена: D:\\local\\work\\whisper_json\\W1_L1_(DL_1_1).json\n",
      "[DEBUG] Итоговый текст сформирован. Длина текста: 4599 символов\n",
      "[INFO] TXT файл сохранён: D:\\local\\work\\whisper_text\\W1_L1_(DL_1_1).txt\n",
      "[INFO] Обработка видео: D:\\local\\input\\W1_L12(DL_1_12).mp4\n",
      "[INFO] JSON транскрипция для видео 'W1_L12(DL_1_12)' не найдена. Запускаем транскрипцию.\n",
      "[INFO] JSON транскрипция сохранена: D:\\local\\work\\whisper_json\\W1_L12(DL_1_12).json\n",
      "[DEBUG] Итоговый текст сформирован. Длина текста: 10491 символов\n",
      "[INFO] TXT файл сохранён: D:\\local\\work\\whisper_text\\W1_L12(DL_1_12).txt\n",
      "[INFO] Обработка видео: D:\\local\\input\\W2_L12 (DL_2_12).mp4\n",
      "[INFO] JSON транскрипция для видео 'W2_L12 (DL_2_12)' не найдена. Запускаем транскрипцию.\n",
      "[INFO] JSON транскрипция сохранена: D:\\local\\work\\whisper_json\\W2_L12_(DL_2_12).json\n",
      "[DEBUG] Итоговый текст сформирован. Длина текста: 7922 символов\n",
      "[INFO] TXT файл сохранён: D:\\local\\work\\whisper_text\\W2_L12_(DL_2_12).txt\n",
      "[INFO] Обработка видео: D:\\local\\input\\WEEK 3 - LEC 12.mp4\n",
      "[INFO] JSON транскрипция для видео 'WEEK 3 - LEC 12' не найдена. Запускаем транскрипцию.\n",
      "[INFO] JSON транскрипция сохранена: D:\\local\\work\\whisper_json\\WEEK_3_-_LEC_12.json\n",
      "[DEBUG] Итоговый текст сформирован. Длина текста: 4280 символов\n",
      "[INFO] TXT файл сохранён: D:\\local\\work\\whisper_text\\WEEK_3_-_LEC_12.txt\n"
     ]
    }
   ],
   "source": [
    "# Каталоги для транскрипции на основе BASE_DIR из config.json\n",
    "video_directory         = BASE_DIR / \"input\"\n",
    "whisper_json_directory  = BASE_DIR / \"work\"  / \"whisper_json\"\n",
    "whisper_text_directory  = BASE_DIR / \"work\"  / \"whisper_text\"\n",
    "extracted_frames_base   = BASE_DIR / \"output\"/ \"images\"\n",
    "\n",
    "# Создаём директории, если ещё нет\n",
    "os.makedirs(whisper_json_directory, exist_ok=True)\n",
    "os.makedirs(whisper_text_directory, exist_ok=True)\n",
    "\n",
    "# Запускаем транскрипцию\n",
    "process_videos_transcription(\n",
    "    str(video_directory),\n",
    "    str(whisper_json_directory),\n",
    "    str(whisper_text_directory)\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
